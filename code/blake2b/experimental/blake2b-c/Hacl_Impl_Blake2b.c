/* 
  This file was generated by KreMLin <https://github.com/FStarLang/kremlin>
  KreMLin invocation: /opt/kremlin/krml -skip-compilation -no-prefix Hacl.Test.Blake2b.Incremental -no-prefix Hacl.Blake2b -bundle Lib.* -bundle Spec.* -bundle C=C.Endianness -library C,FStar -drop LowStar,Spec,Prims,Lib,C.Loops.*,C -add-include "c/Lib_PrintBuffer.h" -tmpdir blake2b-c .output/prims.krml .output/FStar_Pervasives_Native.krml .output/FStar_Pervasives.krml .output/FStar_Preorder.krml .output/FStar_Calc.krml .output/FStar_Squash.krml .output/FStar_Classical.krml .output/FStar_StrongExcludedMiddle.krml .output/FStar_FunctionalExtensionality.krml .output/FStar_List_Tot_Base.krml .output/FStar_List_Tot_Properties.krml .output/FStar_List_Tot.krml .output/FStar_Seq_Base.krml .output/FStar_Seq_Properties.krml .output/FStar_Seq.krml .output/FStar_Mul.krml .output/FStar_Math_Lib.krml .output/FStar_Math_Lemmas.krml .output/FStar_BitVector.krml .output/FStar_UInt.krml .output/FStar_UInt32.krml .output/FStar_Int.krml .output/FStar_Int16.krml .output/FStar_Reflection_Types.krml .output/FStar_Reflection_Data.krml .output/FStar_Order.krml .output/FStar_Reflection_Basic.krml .output/FStar_Ghost.krml .output/FStar_ErasedLogic.krml .output/FStar_UInt64.krml .output/FStar_Exn.krml .output/FStar_Set.krml .output/FStar_Monotonic_Witnessed.krml .output/FStar_PropositionalExtensionality.krml .output/FStar_PredicateExtensionality.krml .output/FStar_TSet.krml .output/FStar_Monotonic_Heap.krml .output/FStar_Heap.krml .output/FStar_ST.krml .output/FStar_All.krml .output/Lib_LoopCombinators.krml .output/FStar_UInt8.krml .output/FStar_Int64.krml .output/FStar_Int63.krml .output/FStar_Int32.krml .output/FStar_Int8.krml .output/FStar_UInt63.krml .output/FStar_UInt16.krml .output/FStar_Int_Cast.krml .output/FStar_UInt128.krml .output/FStar_Int_Cast_Full.krml .output/FStar_Int128.krml .output/Lib_IntTypes.krml .output/Lib_RawIntTypes.krml .output/Lib_Sequence.krml .output/Lib_ByteSequence.krml .output/Spec_Blake2.krml .output/Spec_Blake2_Incremental.krml .output/FStar_Map.krml .output/FStar_Monotonic_HyperHeap.krml .output/FStar_Monotonic_HyperStack.krml .output/FStar_HyperStack.krml .output/FStar_HyperStack_ST.krml .output/FStar_Universe.krml .output/FStar_GSet.krml .output/FStar_ModifiesGen.krml .output/FStar_Range.krml .output/FStar_Tactics_Types.krml .output/FStar_Tactics_Result.krml .output/FStar_Tactics_Effect.krml .output/FStar_Tactics_Util.krml .output/FStar_Reflection_Const.krml .output/FStar_Char.krml .output/FStar_List.krml .output/FStar_String.krml .output/FStar_Reflection_Derived.krml .output/FStar_Tactics_Builtins.krml .output/FStar_Reflection_Formula.krml .output/FStar_Reflection_Derived_Lemmas.krml .output/FStar_Reflection.krml .output/FStar_Tactics_Derived.krml .output/FStar_Tactics_Logic.krml .output/FStar_Tactics.krml .output/FStar_BigOps.krml .output/LowStar_Monotonic_Buffer.krml .output/LowStar_Buffer.krml .output/LowStar_BufferOps.krml .output/FStar_HyperStack_All.krml .output/FStar_Kremlin_Endianness.krml .output/C_Endianness.krml .output/C.krml .output/Spec_Loops.krml .output/C_Loops.krml .output/Lib_Loops.krml .output/LowStar_ImmutableBuffer.krml .output/Lib_Buffer.krml .output/Lib_ByteBuffer.krml .output/Hacl_Impl_Blake2b.krml .output/Hacl_Impl_Blake2b_Incremental.krml .output/Lib_PrintBuffer.krml .output/LowStar_Modifies.krml .output/C_String.krml .output/Hacl_Blake2b.krml .output/Hacl_Test_Blake2b_Incremental.krml
  F* version: 8d4580e6
  KreMLin version: fec2dd6f
 */

#include "Hacl_Impl_Blake2b.h"

uint32_t Hacl_Impl_Blake2b_size_word = (uint32_t)8U;

uint32_t Hacl_Impl_Blake2b_size_block = (uint32_t)16U * (uint32_t)8U;

uint64_t
Hacl_Impl_Blake2b_const_iv[8U] =
  {
    (uint64_t)0x6A09E667F3BCC908U, (uint64_t)0xBB67AE8584CAA73BU, (uint64_t)0x3C6EF372FE94F82BU,
    (uint64_t)0xA54FF53A5F1D36F1U, (uint64_t)0x510E527FADE682D1U, (uint64_t)0x9B05688C2B3E6C1FU,
    (uint64_t)0x1F83D9ABFB41BD6BU, (uint64_t)0x5BE0CD19137E2179U
  };

uint32_t
Hacl_Impl_Blake2b_const_sigma[160U] =
  {
    (uint32_t)0U, (uint32_t)1U, (uint32_t)2U, (uint32_t)3U, (uint32_t)4U, (uint32_t)5U,
    (uint32_t)6U, (uint32_t)7U, (uint32_t)8U, (uint32_t)9U, (uint32_t)10U, (uint32_t)11U,
    (uint32_t)12U, (uint32_t)13U, (uint32_t)14U, (uint32_t)15U, (uint32_t)14U, (uint32_t)10U,
    (uint32_t)4U, (uint32_t)8U, (uint32_t)9U, (uint32_t)15U, (uint32_t)13U, (uint32_t)6U,
    (uint32_t)1U, (uint32_t)12U, (uint32_t)0U, (uint32_t)2U, (uint32_t)11U, (uint32_t)7U,
    (uint32_t)5U, (uint32_t)3U, (uint32_t)11U, (uint32_t)8U, (uint32_t)12U, (uint32_t)0U,
    (uint32_t)5U, (uint32_t)2U, (uint32_t)15U, (uint32_t)13U, (uint32_t)10U, (uint32_t)14U,
    (uint32_t)3U, (uint32_t)6U, (uint32_t)7U, (uint32_t)1U, (uint32_t)9U, (uint32_t)4U,
    (uint32_t)7U, (uint32_t)9U, (uint32_t)3U, (uint32_t)1U, (uint32_t)13U, (uint32_t)12U,
    (uint32_t)11U, (uint32_t)14U, (uint32_t)2U, (uint32_t)6U, (uint32_t)5U, (uint32_t)10U,
    (uint32_t)4U, (uint32_t)0U, (uint32_t)15U, (uint32_t)8U, (uint32_t)9U, (uint32_t)0U,
    (uint32_t)5U, (uint32_t)7U, (uint32_t)2U, (uint32_t)4U, (uint32_t)10U, (uint32_t)15U,
    (uint32_t)14U, (uint32_t)1U, (uint32_t)11U, (uint32_t)12U, (uint32_t)6U, (uint32_t)8U,
    (uint32_t)3U, (uint32_t)13U, (uint32_t)2U, (uint32_t)12U, (uint32_t)6U, (uint32_t)10U,
    (uint32_t)0U, (uint32_t)11U, (uint32_t)8U, (uint32_t)3U, (uint32_t)4U, (uint32_t)13U,
    (uint32_t)7U, (uint32_t)5U, (uint32_t)15U, (uint32_t)14U, (uint32_t)1U, (uint32_t)9U,
    (uint32_t)12U, (uint32_t)5U, (uint32_t)1U, (uint32_t)15U, (uint32_t)14U, (uint32_t)13U,
    (uint32_t)4U, (uint32_t)10U, (uint32_t)0U, (uint32_t)7U, (uint32_t)6U, (uint32_t)3U,
    (uint32_t)9U, (uint32_t)2U, (uint32_t)8U, (uint32_t)11U, (uint32_t)13U, (uint32_t)11U,
    (uint32_t)7U, (uint32_t)14U, (uint32_t)12U, (uint32_t)1U, (uint32_t)3U, (uint32_t)9U,
    (uint32_t)5U, (uint32_t)0U, (uint32_t)15U, (uint32_t)4U, (uint32_t)8U, (uint32_t)6U,
    (uint32_t)2U, (uint32_t)10U, (uint32_t)6U, (uint32_t)15U, (uint32_t)14U, (uint32_t)9U,
    (uint32_t)11U, (uint32_t)3U, (uint32_t)0U, (uint32_t)8U, (uint32_t)12U, (uint32_t)2U,
    (uint32_t)13U, (uint32_t)7U, (uint32_t)1U, (uint32_t)4U, (uint32_t)10U, (uint32_t)5U,
    (uint32_t)10U, (uint32_t)2U, (uint32_t)8U, (uint32_t)4U, (uint32_t)7U, (uint32_t)6U,
    (uint32_t)1U, (uint32_t)5U, (uint32_t)15U, (uint32_t)11U, (uint32_t)9U, (uint32_t)14U,
    (uint32_t)3U, (uint32_t)12U, (uint32_t)13U, (uint32_t)0U
  };

uint32_t
Hacl_Impl_Blake2b_rTable_B[4U] = { (uint32_t)32U, (uint32_t)24U, (uint32_t)16U, (uint32_t)63U };

uint64_t Hacl_Impl_Blake2b_get_iv(uint32_t s)
{
  return Hacl_Impl_Blake2b_const_iv[s];
}

void Hacl_Impl_Blake2b_set_iv(uint64_t *hash)
{
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
  {
    uint64_t *os = hash;
    uint64_t x = Hacl_Impl_Blake2b_const_iv[i];
    os[i] = x;
  }
}

void Hacl_Impl_Blake2b_set_iv_sub(uint64_t *b)
{
  uint64_t *half1 = b + (uint32_t)8U;
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
  {
    uint64_t *os = half1;
    uint64_t x = Hacl_Impl_Blake2b_const_iv[i];
    os[i] = x;
  }
}

uint32_t Hacl_Impl_Blake2b_get_sigma(uint32_t s)
{
  return Hacl_Impl_Blake2b_const_sigma[s];
}

uint32_t Hacl_Impl_Blake2b_get_sigma_sub(uint32_t start, uint32_t i)
{
  uint32_t x0 = start + i;
  return Hacl_Impl_Blake2b_const_sigma[x0];
}

uint32_t Hacl_Impl_Blake2b_get_r(uint32_t s)
{
  return Hacl_Impl_Blake2b_rTable_B[s];
}

void Hacl_Impl_Blake2b_g1(uint64_t *wv, uint32_t a, uint32_t b, uint32_t r)
{
  uint64_t wv_a = wv[a];
  uint64_t wv_b = wv[b];
  wv[a] = (wv_a ^ wv_b) >> r | (wv_a ^ wv_b) << (uint32_t)64U - r;
}

void Hacl_Impl_Blake2b_g2(uint64_t *wv, uint32_t a, uint32_t b, uint64_t x)
{
  uint64_t wv_a = wv[a];
  uint64_t wv_b = wv[b];
  wv[a] = wv_a + wv_b + x;
}

void
Hacl_Impl_Blake2b_blake2_mixing(
  uint64_t *wv,
  uint32_t a,
  uint32_t b,
  uint32_t c,
  uint32_t d,
  uint64_t x,
  uint64_t y
)
{
  uint32_t r0 = Hacl_Impl_Blake2b_rTable_B[0U];
  uint32_t r1 = Hacl_Impl_Blake2b_rTable_B[1U];
  uint32_t r2 = Hacl_Impl_Blake2b_rTable_B[2U];
  uint32_t r3 = Hacl_Impl_Blake2b_rTable_B[3U];
  Hacl_Impl_Blake2b_g2(wv, a, b, x);
  Hacl_Impl_Blake2b_g1(wv, d, a, r0);
  Hacl_Impl_Blake2b_g2(wv, c, d, (uint64_t)0U);
  Hacl_Impl_Blake2b_g1(wv, b, c, r1);
  Hacl_Impl_Blake2b_g2(wv, a, b, y);
  Hacl_Impl_Blake2b_g1(wv, d, a, r2);
  Hacl_Impl_Blake2b_g2(wv, c, d, (uint64_t)0U);
  Hacl_Impl_Blake2b_g1(wv, b, c, r3);
}

void Hacl_Impl_Blake2b_blake2_round1(uint64_t *wv, uint64_t *m, uint32_t i)
{
  uint32_t start_idx = i % (uint32_t)10U * (uint32_t)16U;
  uint32_t x00 = start_idx + (uint32_t)0U;
  uint32_t s0 = Hacl_Impl_Blake2b_const_sigma[x00];
  uint32_t x01 = start_idx + (uint32_t)1U;
  uint32_t s1 = Hacl_Impl_Blake2b_const_sigma[x01];
  uint32_t x02 = start_idx + (uint32_t)2U;
  uint32_t s2 = Hacl_Impl_Blake2b_const_sigma[x02];
  uint32_t x03 = start_idx + (uint32_t)3U;
  uint32_t s3 = Hacl_Impl_Blake2b_const_sigma[x03];
  uint32_t x04 = start_idx + (uint32_t)4U;
  uint32_t s4 = Hacl_Impl_Blake2b_const_sigma[x04];
  uint32_t x05 = start_idx + (uint32_t)5U;
  uint32_t s5 = Hacl_Impl_Blake2b_const_sigma[x05];
  uint32_t x06 = start_idx + (uint32_t)6U;
  uint32_t s6 = Hacl_Impl_Blake2b_const_sigma[x06];
  uint32_t x0 = start_idx + (uint32_t)7U;
  uint32_t s7 = Hacl_Impl_Blake2b_const_sigma[x0];
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)0U,
    (uint32_t)4U,
    (uint32_t)8U,
    (uint32_t)12U,
    m[s0],
    m[s1]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)1U,
    (uint32_t)5U,
    (uint32_t)9U,
    (uint32_t)13U,
    m[s2],
    m[s3]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)2U,
    (uint32_t)6U,
    (uint32_t)10U,
    (uint32_t)14U,
    m[s4],
    m[s5]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)3U,
    (uint32_t)7U,
    (uint32_t)11U,
    (uint32_t)15U,
    m[s6],
    m[s7]);
}

void Hacl_Impl_Blake2b_blake2_round2(uint64_t *wv, uint64_t *m, uint32_t i)
{
  uint32_t start_idx = i % (uint32_t)10U * (uint32_t)16U;
  uint32_t x00 = start_idx + (uint32_t)8U;
  uint32_t s0 = Hacl_Impl_Blake2b_const_sigma[x00];
  uint32_t x01 = start_idx + (uint32_t)9U;
  uint32_t s1 = Hacl_Impl_Blake2b_const_sigma[x01];
  uint32_t x02 = start_idx + (uint32_t)10U;
  uint32_t s2 = Hacl_Impl_Blake2b_const_sigma[x02];
  uint32_t x03 = start_idx + (uint32_t)11U;
  uint32_t s3 = Hacl_Impl_Blake2b_const_sigma[x03];
  uint32_t x04 = start_idx + (uint32_t)12U;
  uint32_t s4 = Hacl_Impl_Blake2b_const_sigma[x04];
  uint32_t x05 = start_idx + (uint32_t)13U;
  uint32_t s5 = Hacl_Impl_Blake2b_const_sigma[x05];
  uint32_t x06 = start_idx + (uint32_t)14U;
  uint32_t s6 = Hacl_Impl_Blake2b_const_sigma[x06];
  uint32_t x0 = start_idx + (uint32_t)15U;
  uint32_t s7 = Hacl_Impl_Blake2b_const_sigma[x0];
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)0U,
    (uint32_t)5U,
    (uint32_t)10U,
    (uint32_t)15U,
    m[s0],
    m[s1]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)1U,
    (uint32_t)6U,
    (uint32_t)11U,
    (uint32_t)12U,
    m[s2],
    m[s3]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)2U,
    (uint32_t)7U,
    (uint32_t)8U,
    (uint32_t)13U,
    m[s4],
    m[s5]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)3U,
    (uint32_t)4U,
    (uint32_t)9U,
    (uint32_t)14U,
    m[s6],
    m[s7]);
}

void Hacl_Impl_Blake2b_blake2_round(uint64_t *wv, uint64_t *m, uint32_t i)
{
  uint32_t start_idx = i % (uint32_t)10U * (uint32_t)16U;
  uint32_t x00 = start_idx + (uint32_t)0U;
  uint32_t s0 = Hacl_Impl_Blake2b_const_sigma[x00];
  uint32_t x01 = start_idx + (uint32_t)1U;
  uint32_t s1 = Hacl_Impl_Blake2b_const_sigma[x01];
  uint32_t x02 = start_idx + (uint32_t)2U;
  uint32_t s2 = Hacl_Impl_Blake2b_const_sigma[x02];
  uint32_t x03 = start_idx + (uint32_t)3U;
  uint32_t s3 = Hacl_Impl_Blake2b_const_sigma[x03];
  uint32_t x04 = start_idx + (uint32_t)4U;
  uint32_t s4 = Hacl_Impl_Blake2b_const_sigma[x04];
  uint32_t x05 = start_idx + (uint32_t)5U;
  uint32_t s5 = Hacl_Impl_Blake2b_const_sigma[x05];
  uint32_t x06 = start_idx + (uint32_t)6U;
  uint32_t s6 = Hacl_Impl_Blake2b_const_sigma[x06];
  uint32_t x07 = start_idx + (uint32_t)7U;
  uint32_t s7 = Hacl_Impl_Blake2b_const_sigma[x07];
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)0U,
    (uint32_t)4U,
    (uint32_t)8U,
    (uint32_t)12U,
    m[s0],
    m[s1]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)1U,
    (uint32_t)5U,
    (uint32_t)9U,
    (uint32_t)13U,
    m[s2],
    m[s3]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)2U,
    (uint32_t)6U,
    (uint32_t)10U,
    (uint32_t)14U,
    m[s4],
    m[s5]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)3U,
    (uint32_t)7U,
    (uint32_t)11U,
    (uint32_t)15U,
    m[s6],
    m[s7]);
  uint32_t start_idx0 = i % (uint32_t)10U * (uint32_t)16U;
  uint32_t x08 = start_idx0 + (uint32_t)8U;
  uint32_t s00 = Hacl_Impl_Blake2b_const_sigma[x08];
  uint32_t x09 = start_idx0 + (uint32_t)9U;
  uint32_t s10 = Hacl_Impl_Blake2b_const_sigma[x09];
  uint32_t x010 = start_idx0 + (uint32_t)10U;
  uint32_t s20 = Hacl_Impl_Blake2b_const_sigma[x010];
  uint32_t x011 = start_idx0 + (uint32_t)11U;
  uint32_t s30 = Hacl_Impl_Blake2b_const_sigma[x011];
  uint32_t x012 = start_idx0 + (uint32_t)12U;
  uint32_t s40 = Hacl_Impl_Blake2b_const_sigma[x012];
  uint32_t x013 = start_idx0 + (uint32_t)13U;
  uint32_t s50 = Hacl_Impl_Blake2b_const_sigma[x013];
  uint32_t x014 = start_idx0 + (uint32_t)14U;
  uint32_t s60 = Hacl_Impl_Blake2b_const_sigma[x014];
  uint32_t x0 = start_idx0 + (uint32_t)15U;
  uint32_t s70 = Hacl_Impl_Blake2b_const_sigma[x0];
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)0U,
    (uint32_t)5U,
    (uint32_t)10U,
    (uint32_t)15U,
    m[s00],
    m[s10]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)1U,
    (uint32_t)6U,
    (uint32_t)11U,
    (uint32_t)12U,
    m[s20],
    m[s30]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)2U,
    (uint32_t)7U,
    (uint32_t)8U,
    (uint32_t)13U,
    m[s40],
    m[s50]);
  Hacl_Impl_Blake2b_blake2_mixing(wv,
    (uint32_t)3U,
    (uint32_t)4U,
    (uint32_t)9U,
    (uint32_t)14U,
    m[s60],
    m[s70]);
}

void
Hacl_Impl_Blake2b_blake2_compress1(
  uint64_t *wv,
  uint64_t *s,
  uint64_t *m,
  FStar_UInt128_uint128 offset1,
  bool flag
)
{
  memcpy(wv, s, (uint32_t)8U * sizeof s[0U]);
  uint64_t *half1 = wv + (uint32_t)8U;
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
  {
    uint64_t *os = half1;
    uint64_t x = Hacl_Impl_Blake2b_const_iv[i];
    os[i] = x;
  }
  uint64_t uu____0 = wv[12U];
  uint64_t wv_12 = uu____0 ^ FStar_UInt128_uint128_to_uint64(offset1);
  uint64_t uu____1 = wv[13U];
  uint64_t
  wv_13 =
    uu____1
    ^ FStar_UInt128_uint128_to_uint64(FStar_UInt128_shift_right(offset1, (uint32_t)64U));
  uint64_t wv_14 = wv[14U] ^ (uint64_t)0xFFFFFFFFFFFFFFFFU;
  wv[12U] = wv_12;
  wv[13U] = wv_13;
  if (flag)
    wv[14U] = wv_14;
}

void Hacl_Impl_Blake2b_blake2_compress2(uint64_t *wv, uint64_t *m)
{
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)12U; i = i + (uint32_t)1U)
    Hacl_Impl_Blake2b_blake2_round(wv, m, i);
}

void Hacl_Impl_Blake2b_blake2_compress3_inner(uint64_t *wv, uint32_t i, uint64_t *s)
{
  uint32_t i_plus_8 = i + (uint32_t)8U;
  uint64_t hi_xor_wvi = s[i] ^ wv[i];
  uint64_t hi = hi_xor_wvi ^ wv[i_plus_8];
  s[i] = hi;
}

void Hacl_Impl_Blake2b_blake2_compress3(uint64_t *wv, uint64_t *s)
{
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
  {
    uint32_t i_plus_8 = i + (uint32_t)8U;
    uint64_t hi_xor_wvi = s[i] ^ wv[i];
    uint64_t hi = hi_xor_wvi ^ wv[i_plus_8];
    s[i] = hi;
  }
}

void
Hacl_Impl_Blake2b_blake2_compress(
  uint64_t *s,
  uint64_t *m,
  FStar_UInt128_uint128 offset1,
  bool flag
)
{
  uint64_t b[16U] = { 0U };
  memcpy(b, s, (uint32_t)8U * sizeof s[0U]);
  uint64_t *half1 = b + (uint32_t)8U;
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
  {
    uint64_t *os = half1;
    uint64_t x = Hacl_Impl_Blake2b_const_iv[i];
    os[i] = x;
  }
  uint64_t uu____0 = b[12U];
  uint64_t wv_12 = uu____0 ^ FStar_UInt128_uint128_to_uint64(offset1);
  uint64_t uu____1 = b[13U];
  uint64_t
  wv_13 =
    uu____1
    ^ FStar_UInt128_uint128_to_uint64(FStar_UInt128_shift_right(offset1, (uint32_t)64U));
  uint64_t wv_14 = b[14U] ^ (uint64_t)0xFFFFFFFFFFFFFFFFU;
  b[12U] = wv_12;
  b[13U] = wv_13;
  if (flag)
    b[14U] = wv_14;
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)12U; i = i + (uint32_t)1U)
    Hacl_Impl_Blake2b_blake2_round(b, m, i);
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
  {
    uint32_t i_plus_8 = i + (uint32_t)8U;
    uint64_t hi_xor_wvi = s[i] ^ b[i];
    uint64_t hi = hi_xor_wvi ^ b[i_plus_8];
    s[i] = hi;
  }
  memset(b, 0U, (uint32_t)16U * sizeof b[0U]);
}

void
Hacl_Impl_Blake2b_blake2b_update_block(uint64_t *hash, FStar_UInt128_uint128 prev, uint8_t *d)
{
  uint64_t b[16U] = { 0U };
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)16U; i = i + (uint32_t)1U)
  {
    uint64_t *os = b;
    uint8_t *bj = d + i * (uint32_t)8U;
    uint64_t u = load64_le(bj);
    uint64_t r = u;
    uint64_t x = r;
    os[i] = x;
  }
  FStar_UInt128_uint128 offset1 = prev;
  Hacl_Impl_Blake2b_blake2_compress(hash, b, offset1, false);
  memset(b, 0U, (uint32_t)16U * sizeof b[0U]);
}

void Hacl_Impl_Blake2b_blake2b_init_hash(uint64_t *hash, uint32_t kk, uint32_t nn)
{
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
  {
    uint64_t *os = hash;
    uint64_t x = Hacl_Impl_Blake2b_const_iv[i];
    os[i] = x;
  }
  uint64_t s0 = hash[0U];
  uint64_t kk_shift_8 = (uint64_t)kk << (uint32_t)8U;
  uint64_t s0_ = s0 ^ (uint64_t)0x01010000U ^ kk_shift_8 ^ (uint64_t)nn;
  hash[0U] = s0_;
}

void
Hacl_Impl_Blake2b_blake2b_init_branching(
  uint64_t *hash,
  uint8_t *key_block,
  uint32_t kk,
  uint8_t *k,
  uint32_t nn
)
{
  if (!(kk == (uint32_t)0U))
  {
    memcpy(key_block, k, kk * sizeof k[0U]);
    uint64_t prev64 = (uint64_t)((uint32_t)16U * (uint32_t)8U);
    Hacl_Impl_Blake2b_blake2b_update_block(hash,
      FStar_UInt128_uint64_to_uint128(prev64),
      key_block);
  }
}

void Hacl_Impl_Blake2b_blake2b_init(uint64_t *hash, uint32_t kk, uint8_t *k, uint32_t nn)
{
  KRML_CHECK_SIZE(sizeof (uint8_t), (uint32_t)16U * (uint32_t)8U);
  uint8_t b[(uint32_t)16U * (uint32_t)8U];
  memset(b, 0U, (uint32_t)16U * (uint32_t)8U * sizeof b[0U]);
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
  {
    uint64_t *os = hash;
    uint64_t x = Hacl_Impl_Blake2b_const_iv[i];
    os[i] = x;
  }
  uint64_t s0 = hash[0U];
  uint64_t kk_shift_8 = (uint64_t)kk << (uint32_t)8U;
  uint64_t s0_ = s0 ^ (uint64_t)0x01010000U ^ kk_shift_8 ^ (uint64_t)nn;
  hash[0U] = s0_;
  if (!(kk == (uint32_t)0U))
  {
    memcpy(b, k, kk * sizeof k[0U]);
    uint64_t prev64 = (uint64_t)((uint32_t)16U * (uint32_t)8U);
    Hacl_Impl_Blake2b_blake2b_update_block(hash, FStar_UInt128_uint64_to_uint128(prev64), b);
  }
  memset(b, 0U, (uint32_t)16U * (uint32_t)8U * sizeof b[0U]);
}

void
Hacl_Impl_Blake2b_blake2b_update_last(
  uint64_t *hash,
  FStar_UInt128_uint128 prev,
  uint32_t len,
  uint8_t *last1
)
{
  KRML_CHECK_SIZE(sizeof (uint8_t), (uint32_t)16U * (uint32_t)8U);
  uint8_t last_block[(uint32_t)16U * (uint32_t)8U];
  memset(last_block, 0U, (uint32_t)16U * (uint32_t)8U * sizeof last_block[0U]);
  uint64_t last_block_w[16U] = { 0U };
  memcpy(last_block, last1, len * sizeof last1[0U]);
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)16U; i = i + (uint32_t)1U)
  {
    uint64_t *os = last_block_w;
    uint8_t *bj = last_block + i * (uint32_t)8U;
    uint64_t u = load64_le(bj);
    uint64_t r = u;
    uint64_t x = r;
    os[i] = x;
  }
  FStar_UInt128_uint128 offset1 = prev;
  Hacl_Impl_Blake2b_blake2_compress(hash, last_block_w, offset1, true);
}

void Hacl_Impl_Blake2b_blake2b_finish(uint32_t nn, uint8_t *output, uint64_t *hash)
{
  uint8_t b[64U] = { 0U };
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
    store64_le(b + i * (uint32_t)8U, hash[i]);
  uint8_t *final = b;
  memcpy(output, final, nn * sizeof final[0U]);
  memset(b, 0U, (uint32_t)64U * sizeof b[0U]);
}

void Hacl_Impl_Blake2b_blake2b_update(uint64_t *hash, uint32_t ll, uint8_t *d, uint32_t kk)
{
  uint32_t klen;
  if (kk == (uint32_t)0U)
    klen = (uint32_t)0U;
  else
    klen = (uint32_t)1U;
  uint32_t nb = ll / ((uint32_t)16U * (uint32_t)8U);
  uint32_t rem1 = ll % ((uint32_t)16U * (uint32_t)8U);
  for (uint32_t i = (uint32_t)0U; i < nb; i = i + (uint32_t)1U)
  {
    uint8_t *block = d + i * (uint32_t)16U * (uint32_t)8U;
    uint32_t p1 = klen + i + (uint32_t)1U;
    uint64_t p64 = (uint64_t)p1 * (uint64_t)128U;
    FStar_UInt128_uint128 p = FStar_UInt128_uint64_to_uint128(p64);
    Hacl_Impl_Blake2b_blake2b_update_block(hash, p, block);
  }
  uint8_t *last1 = d + nb * (uint32_t)16U * (uint32_t)8U;
  Hacl_Impl_Blake2b_blake2b_update_last(hash,
    FStar_UInt128_add_mod(FStar_UInt128_uint64_to_uint128((uint64_t)ll),
      FStar_UInt128_uint64_to_uint128((uint64_t)(klen * (uint32_t)128U))),
    rem1,
    last1);
}

void
Hacl_Impl_Blake2b_blake2b(
  uint32_t nn,
  uint8_t *output,
  uint32_t ll,
  uint8_t *d,
  uint32_t kk,
  uint8_t *k
)
{
  uint64_t b0[8U] = { 0U };
  KRML_CHECK_SIZE(sizeof (uint8_t), (uint32_t)16U * (uint32_t)8U);
  uint8_t b[(uint32_t)16U * (uint32_t)8U];
  memset(b, 0U, (uint32_t)16U * (uint32_t)8U * sizeof b[0U]);
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
  {
    uint64_t *os = b0;
    uint64_t x = Hacl_Impl_Blake2b_const_iv[i];
    os[i] = x;
  }
  uint64_t s0 = b0[0U];
  uint64_t kk_shift_8 = (uint64_t)kk << (uint32_t)8U;
  uint64_t s0_ = s0 ^ (uint64_t)0x01010000U ^ kk_shift_8 ^ (uint64_t)nn;
  b0[0U] = s0_;
  if (!(kk == (uint32_t)0U))
  {
    memcpy(b, k, kk * sizeof k[0U]);
    uint64_t prev64 = (uint64_t)((uint32_t)16U * (uint32_t)8U);
    Hacl_Impl_Blake2b_blake2b_update_block(b0, FStar_UInt128_uint64_to_uint128(prev64), b);
  }
  memset(b, 0U, (uint32_t)16U * (uint32_t)8U * sizeof b[0U]);
  uint32_t klen;
  if (kk == (uint32_t)0U)
    klen = (uint32_t)0U;
  else
    klen = (uint32_t)1U;
  uint32_t nb = ll / ((uint32_t)16U * (uint32_t)8U);
  uint32_t rem1 = ll % ((uint32_t)16U * (uint32_t)8U);
  for (uint32_t i = (uint32_t)0U; i < nb; i = i + (uint32_t)1U)
  {
    uint8_t *block = d + i * (uint32_t)16U * (uint32_t)8U;
    uint32_t p1 = klen + i + (uint32_t)1U;
    uint64_t p64 = (uint64_t)p1 * (uint64_t)128U;
    FStar_UInt128_uint128 p = FStar_UInt128_uint64_to_uint128(p64);
    Hacl_Impl_Blake2b_blake2b_update_block(b0, p, block);
  }
  uint8_t *last1 = d + nb * (uint32_t)16U * (uint32_t)8U;
  Hacl_Impl_Blake2b_blake2b_update_last(b0,
    FStar_UInt128_add_mod(FStar_UInt128_uint64_to_uint128((uint64_t)ll),
      FStar_UInt128_uint64_to_uint128((uint64_t)(klen * (uint32_t)128U))),
    rem1,
    last1);
  Hacl_Impl_Blake2b_blake2b_finish(nn, output, b0);
  memset(b0, 0U, (uint32_t)8U * sizeof b0[0U]);
}

