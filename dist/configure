#!/usr/bin/env bash

set -o pipefail
set -e

# This script mostly detects the presence of ocamlfind as well as various ocaml
# packages

detect_ocamlfind () {
  package=$1
  loc=$(ocamlfind query $package)
  r=$?
  if [[ $r == 0 ]]; then
    echo "... found $package in $loc"
  else
    echo "OCaml package $package not found"
  fi
  return $r
}

detect_ocaml () {
  # Detect ocamlfind
  loc=$(which ocamlfind)
  r=$?
  if [[ $r == 0 ]]; then
    echo "... found ocamlfind in $loc"
  else
    echo "ocamlfind not found"
    return 1
  fi
  # Detect packages
  for p in ctypes ctypes.foreign; do
    detect_ocamlfind $p || return 1
  done
}

detect_uint128 () {
  local file=$(mktemp /tmp/testint128.XXXXXXX).c
  echo "unsigned __int128 x = 0;" > $file
  cc -c $file -o /dev/null
}

detect_x64 () {
  [[ $(uname -m) == "x86_64" ]]
}

detect_arm () {
  [[ $(uname -m | cut -c 1-3) == "arm" ]] || [[ $(uname -m | cut -c 1-7) == "aarch64" ]];
}

detect_arm_cc () {
  local file=$(mktemp /tmp/testvec128.XXXXXXX).c
  cat > $file <<EOF
#include <libintvector.h>

int main () {
  uint8_t block[32] = { 0 };
  Lib_IntVector_Intrinsics_vec128 b1 = Lib_IntVector_Intrinsics_vec128_load_le(block);
  Lib_IntVector_Intrinsics_vec128 b2 = Lib_IntVector_Intrinsics_vec128_load_le(block + 16);
  Lib_IntVector_Intrinsics_vec128 test = Lib_IntVector_Intrinsics_vec128_interleave_high64(b1, b2);
  return 0;
}
EOF
  cc -I. -march=armv8-a+simd -c $file -o /dev/null
}

detect_broken_xcode () {
  local file=$(mktemp /tmp/testasm.XXXXXXX).c
  cat > $file <<EOF
#include <inttypes.h>

extern void fsqr2 (uint64_t *out, uint64_t *f, uint64_t *tmp) 
{
  asm volatile(
    // Step 1: Compute all partial products
    "  movq 0(%1), %%rdx;"                                       // f[0]
    "  mulxq 8(%1), %%r8, %%r14;"      "  xor %%r15, %%r15;"     // f[1]*f[0]
    "  mulxq 16(%1), %%r9, %%r10;"     "  adcx %%r14, %%r9;"     // f[2]*f[0]
    "  mulxq 24(%1), %%rax, %%rcx;"    "  adcx %%rax, %%r10;"    // f[3]*f[0]
    "  movq 24(%1), %%rdx;"                                      // f[3]
    "  mulxq 8(%1), %%r11, %%rbx;"     "  adcx %%rcx, %%r11;"    // f[1]*f[3]
    "  mulxq 16(%1), %%rax, %%r13;"    "  adcx %%rax, %%rbx;"    // f[2]*f[3]
    "  movq 8(%1), %%rdx;"             "  adcx %%r15, %%r13;"    // f1
    "  mulxq 16(%1), %%rax, %%rcx;"    "  mov $0, %%r14;"        // f[2]*f[1]

    // Step 2: Compute two parallel carry chains
    "  xor %%r15, %%r15;"
    "  adox %%rax, %%r10;"
    "  adcx %%r8, %%r8;"
    "  adox %%rcx, %%r11;"
    "  adcx %%r9, %%r9;"
    "  adox %%r15, %%rbx;"
    "  adcx %%r10, %%r10;"
    "  adox %%r15, %%r13;"
    "  adcx %%r11, %%r11;"
    "  adox %%r15, %%r14;"
    "  adcx %%rbx, %%rbx;"
    "  adcx %%r13, %%r13;"
    "  adcx %%r14, %%r14;"

    // Step 3: Compute intermediate squares
    "  movq 0(%1), %%rdx;"     "  mulx %%rdx, %%rax, %%rcx;"    // f[0]^2
                               "  movq %%rax, 0(%2);"
    "  add %%rcx, %%r8;"       "  movq %%r8, 8(%2);"
    "  movq 8(%1), %%rdx;"     "  mulx %%rdx, %%rax, %%rcx;"    // f[1]^2
    "  adcx %%rax, %%r9;"      "  movq %%r9, 16(%2);"
    "  adcx %%rcx, %%r10;"     "  movq %%r10, 24(%2);"
    "  movq 16(%1), %%rdx;"    "  mulx %%rdx, %%rax, %%rcx;"    // f[2]^2
    "  adcx %%rax, %%r11;"     "  movq %%r11, 32(%2);"
    "  adcx %%rcx, %%rbx;"     "  movq %%rbx, 40(%2);"
    "  movq 24(%1), %%rdx;"    "  mulx %%rdx, %%rax, %%rcx;"    // f[3]^2
    "  adcx %%rax, %%r13;"     "  movq %%r13, 48(%2);"
    "  adcx %%rcx, %%r14;"     "  movq %%r14, 56(%2);"

    // Step 1: Compute all partial products
    "  movq 32(%1), %%rdx;"                                       // f[0]
    "  mulxq 40(%1), %%r8, %%r14;"      "  xor %%r15, %%r15;"     // f[1]*f[0]
    "  mulxq 48(%1), %%r9, %%r10;"     "  adcx %%r14, %%r9;"     // f[2]*f[0]
    "  mulxq 56(%1), %%rax, %%rcx;"    "  adcx %%rax, %%r10;"    // f[3]*f[0]
    "  movq 56(%1), %%rdx;"                                      // f[3]
    "  mulxq 40(%1), %%r11, %%rbx;"     "  adcx %%rcx, %%r11;"    // f[1]*f[3]
    "  mulxq 48(%1), %%rax, %%r13;"    "  adcx %%rax, %%rbx;"    // f[2]*f[3]
    "  movq 40(%1), %%rdx;"             "  adcx %%r15, %%r13;"    // f1
    "  mulxq 48(%1), %%rax, %%rcx;"    "  mov $0, %%r14;"        // f[2]*f[1]

    // Step 2: Compute two parallel carry chains
    "  xor %%r15, %%r15;"
    "  adox %%rax, %%r10;"
    "  adcx %%r8, %%r8;"
    "  adox %%rcx, %%r11;"
    "  adcx %%r9, %%r9;"
    "  adox %%r15, %%rbx;"
    "  adcx %%r10, %%r10;"
    "  adox %%r15, %%r13;"
    "  adcx %%r11, %%r11;"
    "  adox %%r15, %%r14;"
    "  adcx %%rbx, %%rbx;"
    "  adcx %%r13, %%r13;"
    "  adcx %%r14, %%r14;"

    // Step 3: Compute intermediate squares
    "  movq 32(%1), %%rdx;"     "  mulx %%rdx, %%rax, %%rcx;"    // f[0]^2
                               "  movq %%rax, 64(%2);"
    "  add %%rcx, %%r8;"       "  movq %%r8, 72(%2);"
    "  movq 40(%1), %%rdx;"     "  mulx %%rdx, %%rax, %%rcx;"    // f[1]^2
    "  adcx %%rax, %%r9;"      "  movq %%r9, 80(%2);"
    "  adcx %%rcx, %%r10;"     "  movq %%r10, 88(%2);"
    "  movq 48(%1), %%rdx;"    "  mulx %%rdx, %%rax, %%rcx;"    // f[2]^2
    "  adcx %%rax, %%r11;"     "  movq %%r11, 96(%2);"
    "  adcx %%rcx, %%rbx;"     "  movq %%rbx, 104(%2);"
    "  movq 56(%1), %%rdx;"    "  mulx %%rdx, %%rax, %%rcx;"    // f[3]^2
    "  adcx %%rax, %%r13;"     "  movq %%r13, 112(%2);"
    "  adcx %%rcx, %%r14;"     "  movq %%r14, 120(%2);"

    // Line up pointers
    "  mov %2, %1;"
    "  mov %0, %2;"

    // Step 1: Compute dst + carry == tmp_hi * 38 + tmp_lo
    "  mov $38, %%rdx;"
    "  mulxq 32(%1), %%r8, %%r13;"
    "  xor %%rcx, %%rcx;"
    "  adoxq 0(%1), %%r8;"
    "  mulxq 40(%1), %%r9, %%rbx;"
    "  adcx %%r13, %%r9;"
    "  adoxq 8(%1), %%r9;"
    "  mulxq 48(%1), %%r10, %%r13;"
    "  adcx %%rbx, %%r10;"
    "  adoxq 16(%1), %%r10;"
    "  mulxq 56(%1), %%r11, %%rax;"
    "  adcx %%r13, %%r11;"
    "  adoxq 24(%1), %%r11;"
    "  adcx %%rcx, %%rax;"
    "  adox %%rcx, %%rax;"
    "  imul %%rdx, %%rax;"

    // Step 2: Fold the carry back into dst
    "  add %%rax, %%r8;"
    "  adcx %%rcx, %%r9;"
    "  movq %%r9, 8(%2);"
    "  adcx %%rcx, %%r10;"
    "  movq %%r10, 16(%2);"
    "  adcx %%rcx, %%r11;"
    "  movq %%r11, 24(%2);"

    // Step 3: Fold the carry bit back in; guaranteed not to carry at this point
    "  mov $0, %%rax;"
    "  cmovc %%rdx, %%rax;"
    "  add %%rax, %%r8;"
    "  movq %%r8, 0(%2);"

    // Step 1: Compute dst + carry == tmp_hi * 38 + tmp_lo
    "  mov $38, %%rdx;"
    "  mulxq 96(%1), %%r8, %%r13;"
    "  xor %%rcx, %%rcx;"
    "  adoxq 64(%1), %%r8;"
    "  mulxq 104(%1), %%r9, %%rbx;"
    "  adcx %%r13, %%r9;"
    "  adoxq 72(%1), %%r9;"
    "  mulxq 112(%1), %%r10, %%r13;"
    "  adcx %%rbx, %%r10;"
    "  adoxq 80(%1), %%r10;"
    "  mulxq 120(%1), %%r11, %%rax;"
    "  adcx %%r13, %%r11;"
    "  adoxq 88(%1), %%r11;"
    "  adcx %%rcx, %%rax;"
    "  adox %%rcx, %%rax;"
    "  imul %%rdx, %%rax;"

    // Step 2: Fold the carry back into dst
    "  add %%rax, %%r8;"
    "  adcx %%rcx, %%r9;"
    "  movq %%r9, 40(%2);"
    "  adcx %%rcx, %%r10;"
    "  movq %%r10, 48(%2);"
    "  adcx %%rcx, %%r11;"
    "  movq %%r11, 56(%2);"

    // Step 3: Fold the carry bit back in; guaranteed not to carry at this point
    "  mov $0, %%rax;"
    "  cmovc %%rdx, %%rax;"
    "  add %%rax, %%r8;"
    "  movq %%r8, 32(%2);"
  : "+&r" (out), "+&r" (f), "+&r" (tmp)
  : 
  : "%rax", "%rbx", "%rcx", "%rdx", "%r8", "%r9", "%r10", "%r11", "%r13", "%r14", "%r15", "memory", "cc"
  );
}
EOF
  cc -O3 -c $file -o /dev/null
}

# Main auto-detection

echo -n > Makefile.config
echo -n > config.h

if detect_arm; then
  echo "... detected ARM platform"
  echo "... $(uname -m) does not support 256-bit arithmetic"
  echo "BLACKLIST += $(ls *CP256*.c *_256.c *_Vec256.c | xargs)" >> Makefile.config
  echo "... $(uname -m) does not support legacy vale stubs"
  echo "BLACKLIST += evercrypt_vale_stubs.c" >> Makefile.config
  echo "CFLAGS += -DLib_IntVector_Intrinsics_vec256=\"void *\"" >> Makefile.config
  if detect_arm_cc; then
    echo "... cc can cross-compile to ARM64 with SIMD"
    echo "CFLAGS_128 = -march=armv8-a+simd" >> Makefile.config
  else
    echo "cc cannot compile 128-bit vector arithmetic, disabling"
    echo "BLACKLIST += $(ls *CP128*.c *_128.c *_Vec128.c | xargs)" >> Makefile.config
  fi
fi

if ! detect_x64; then
  echo "$(uname -m) does not support x64 assembly, disabling Curve64"
  echo "BLACKLIST += Hacl_Curve25519_64.c $(ls Hacl_HPKE_Curve64_*.c | xargs)" >> Makefile.config
  echo "$(uname -m) does not support _addcarry_u64, disabling ECDSA"
  echo "BLACKLIST += Hacl_ECDSA.c $(ls Hacl_HPKE_P256_*.c | xargs)" >> Makefile.config
else
  if ! detect_broken_xcode; then
    echo -n "register allocation seems broken (are you using XCode 10.1?)... "
    echo "disabling inline assembly"
    echo "#define BROKEN_INLINE_ASM 1" >> config.h
  else
    echo "... compiler can compile inline assembly"
  fi
fi

if ! detect_uint128; then
  # Explicitly not supporting compilation with MSVC, which would entail not
  # defining KRML_VERIFIED_UINT128.
  echo "cc does not support unsigned __int128 -- using a fallback verified implementation"
  echo "CFLAGS += -DKRML_VERIFIED_UINT128" >> Makefile.config
fi

if ! detect_ocaml; then
  echo "OCaml bindings disabled"
  echo "DISABLE_OCAML_BINDINGS=1" >> Makefile.config
fi
