/* MIT License
 *
 * Copyright (c) 2016-2020 INRIA, CMU and Microsoft Corporation
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */


#include "Hacl_Streaming_Poly1305_32.h"

typedef struct Hacl_Streaming_Functor_state_s___uint64_t___uint8_t__s
{
  uint64_t *block_state;
  uint8_t *buf;
  uint64_t total_len;
  uint8_t *maybe_key;
}
Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_;

Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_
*Hacl_Streaming_Poly1305_32_create_in(uint8_t *k1)
{
  uint8_t *buf1 = KRML_HOST_CALLOC((uint32_t)16U, sizeof (uint8_t));
  uint8_t dummy_key[32U] = { 0U };
  uint64_t *r10 = KRML_HOST_CALLOC((uint32_t)25U, sizeof (uint64_t));
  uint64_t *acc0 = r10;
  uint64_t *pre0 = r10 + (uint32_t)5U;
  uint8_t *kr0 = dummy_key;
  acc0[0U] = (uint64_t)0U;
  acc0[1U] = (uint64_t)0U;
  acc0[2U] = (uint64_t)0U;
  acc0[3U] = (uint64_t)0U;
  acc0[4U] = (uint64_t)0U;
  uint64_t u20 = load64_le(kr0);
  uint64_t lo = u20;
  uint64_t u21 = load64_le(kr0 + (uint32_t)8U);
  uint64_t hi = u21;
  uint64_t mask00 = (uint64_t)0x0ffffffc0fffffffU;
  uint64_t mask10 = (uint64_t)0x0ffffffc0ffffffcU;
  uint64_t lo10 = lo & mask00;
  uint64_t hi10 = hi & mask10;
  uint64_t *r2 = pre0;
  uint64_t *r50 = pre0 + (uint32_t)5U;
  uint64_t *rn0 = pre0 + (uint32_t)10U;
  uint64_t *rn_50 = pre0 + (uint32_t)15U;
  uint64_t r_vec00 = lo10;
  uint64_t r_vec10 = hi10;
  uint64_t f00 = r_vec00 & (uint64_t)0x3ffffffU;
  uint64_t f10 = r_vec00 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
  uint64_t f20 = r_vec00 >> (uint32_t)52U | (r_vec10 & (uint64_t)0x3fffU) << (uint32_t)12U;
  uint64_t f30 = r_vec10 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
  uint64_t f40 = r_vec10 >> (uint32_t)40U;
  uint64_t f01 = f00;
  uint64_t f11 = f10;
  uint64_t f25 = f20;
  uint64_t f31 = f30;
  uint64_t f41 = f40;
  r2[0U] = f01;
  r2[1U] = f11;
  r2[2U] = f25;
  r2[3U] = f31;
  r2[4U] = f41;
  uint64_t f200 = r2[0U];
  uint64_t f210 = r2[1U];
  uint64_t f220 = r2[2U];
  uint64_t f230 = r2[3U];
  uint64_t f240 = r2[4U];
  r50[0U] = f200 * (uint64_t)5U;
  r50[1U] = f210 * (uint64_t)5U;
  r50[2U] = f220 * (uint64_t)5U;
  r50[3U] = f230 * (uint64_t)5U;
  r50[4U] = f240 * (uint64_t)5U;
  rn0[0U] = r2[0U];
  rn0[1U] = r2[1U];
  rn0[2U] = r2[2U];
  rn0[3U] = r2[3U];
  rn0[4U] = r2[4U];
  rn_50[0U] = r50[0U];
  rn_50[1U] = r50[1U];
  rn_50[2U] = r50[2U];
  rn_50[3U] = r50[3U];
  rn_50[4U] = r50[4U];
  uint64_t *block_state = r10;
  uint8_t *k_ = KRML_HOST_CALLOC((uint32_t)32U, sizeof (uint8_t));
  memcpy(k_, k1, (uint32_t)32U * sizeof (k1[0U]));
  uint8_t *k_0 = k_;
  Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_
  s = { .block_state = block_state, .buf = buf1, .total_len = (uint64_t)0U, .maybe_key = k_0 };
  KRML_CHECK_SIZE(sizeof (Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_), (uint32_t)1U);
  Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_
  *p = KRML_HOST_MALLOC(sizeof (Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_));
  p[0U] = s;
  uint64_t *acc = block_state;
  uint64_t *pre = block_state + (uint32_t)5U;
  uint8_t *kr = k1;
  acc[0U] = (uint64_t)0U;
  acc[1U] = (uint64_t)0U;
  acc[2U] = (uint64_t)0U;
  acc[3U] = (uint64_t)0U;
  acc[4U] = (uint64_t)0U;
  uint64_t u22 = load64_le(kr);
  uint64_t lo0 = u22;
  uint64_t u2 = load64_le(kr + (uint32_t)8U);
  uint64_t hi0 = u2;
  uint64_t mask0 = (uint64_t)0x0ffffffc0fffffffU;
  uint64_t mask1 = (uint64_t)0x0ffffffc0ffffffcU;
  uint64_t lo1 = lo0 & mask0;
  uint64_t hi1 = hi0 & mask1;
  uint64_t *r1 = pre;
  uint64_t *r5 = pre + (uint32_t)5U;
  uint64_t *rn = pre + (uint32_t)10U;
  uint64_t *rn_5 = pre + (uint32_t)15U;
  uint64_t r_vec0 = lo1;
  uint64_t r_vec1 = hi1;
  uint64_t f02 = r_vec0 & (uint64_t)0x3ffffffU;
  uint64_t f12 = r_vec0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
  uint64_t f26 = r_vec0 >> (uint32_t)52U | (r_vec1 & (uint64_t)0x3fffU) << (uint32_t)12U;
  uint64_t f32 = r_vec1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
  uint64_t f42 = r_vec1 >> (uint32_t)40U;
  uint64_t f0 = f02;
  uint64_t f1 = f12;
  uint64_t f2 = f26;
  uint64_t f3 = f32;
  uint64_t f4 = f42;
  r1[0U] = f0;
  r1[1U] = f1;
  r1[2U] = f2;
  r1[3U] = f3;
  r1[4U] = f4;
  uint64_t f201 = r1[0U];
  uint64_t f21 = r1[1U];
  uint64_t f22 = r1[2U];
  uint64_t f23 = r1[3U];
  uint64_t f24 = r1[4U];
  r5[0U] = f201 * (uint64_t)5U;
  r5[1U] = f21 * (uint64_t)5U;
  r5[2U] = f22 * (uint64_t)5U;
  r5[3U] = f23 * (uint64_t)5U;
  r5[4U] = f24 * (uint64_t)5U;
  rn[0U] = r1[0U];
  rn[1U] = r1[1U];
  rn[2U] = r1[2U];
  rn[3U] = r1[3U];
  rn[4U] = r1[4U];
  rn_5[0U] = r5[0U];
  rn_5[1U] = r5[1U];
  rn_5[2U] = r5[2U];
  rn_5[3U] = r5[3U];
  rn_5[4U] = r5[4U];
  return p;
}

void
Hacl_Streaming_Poly1305_32_init(
  uint8_t *k1,
  Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ *s
)
{
  Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ scrut = *s;
  uint8_t *k_ = scrut.maybe_key;
  uint8_t *buf1 = scrut.buf;
  uint64_t *block_state = scrut.block_state;
  uint64_t *acc = block_state;
  uint64_t *pre = block_state + (uint32_t)5U;
  uint8_t *kr = k1;
  acc[0U] = (uint64_t)0U;
  acc[1U] = (uint64_t)0U;
  acc[2U] = (uint64_t)0U;
  acc[3U] = (uint64_t)0U;
  acc[4U] = (uint64_t)0U;
  uint64_t u20 = load64_le(kr);
  uint64_t lo = u20;
  uint64_t u2 = load64_le(kr + (uint32_t)8U);
  uint64_t hi = u2;
  uint64_t mask0 = (uint64_t)0x0ffffffc0fffffffU;
  uint64_t mask1 = (uint64_t)0x0ffffffc0ffffffcU;
  uint64_t lo1 = lo & mask0;
  uint64_t hi1 = hi & mask1;
  uint64_t *r = pre;
  uint64_t *r5 = pre + (uint32_t)5U;
  uint64_t *rn = pre + (uint32_t)10U;
  uint64_t *rn_5 = pre + (uint32_t)15U;
  uint64_t r_vec0 = lo1;
  uint64_t r_vec1 = hi1;
  uint64_t f00 = r_vec0 & (uint64_t)0x3ffffffU;
  uint64_t f10 = r_vec0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
  uint64_t f20 = r_vec0 >> (uint32_t)52U | (r_vec1 & (uint64_t)0x3fffU) << (uint32_t)12U;
  uint64_t f30 = r_vec1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
  uint64_t f40 = r_vec1 >> (uint32_t)40U;
  uint64_t f0 = f00;
  uint64_t f1 = f10;
  uint64_t f2 = f20;
  uint64_t f3 = f30;
  uint64_t f4 = f40;
  r[0U] = f0;
  r[1U] = f1;
  r[2U] = f2;
  r[3U] = f3;
  r[4U] = f4;
  uint64_t f200 = r[0U];
  uint64_t f21 = r[1U];
  uint64_t f22 = r[2U];
  uint64_t f23 = r[3U];
  uint64_t f24 = r[4U];
  r5[0U] = f200 * (uint64_t)5U;
  r5[1U] = f21 * (uint64_t)5U;
  r5[2U] = f22 * (uint64_t)5U;
  r5[3U] = f23 * (uint64_t)5U;
  r5[4U] = f24 * (uint64_t)5U;
  rn[0U] = r[0U];
  rn[1U] = r[1U];
  rn[2U] = r[2U];
  rn[3U] = r[3U];
  rn[4U] = r[4U];
  rn_5[0U] = r5[0U];
  rn_5[1U] = r5[1U];
  rn_5[2U] = r5[2U];
  rn_5[3U] = r5[3U];
  rn_5[4U] = r5[4U];
  memcpy(k_, k1, (uint32_t)32U * sizeof (k1[0U]));
  uint8_t *k_1 = k_;
  s[0U] =
    (
      (Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_){
        .block_state = block_state,
        .buf = buf1,
        .total_len = (uint64_t)0U,
        .maybe_key = k_1
      }
    );
}

void
Hacl_Streaming_Poly1305_32_update(
  Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ *p,
  uint8_t *data,
  uint32_t len
)
{
  Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ s = *p;
  uint64_t total_len = s.total_len;
  uint64_t x5 = total_len % (uint64_t)(uint32_t)16U;
  uint32_t sz = (uint32_t)x5;
  if (len < (uint32_t)16U - sz)
  {
    Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ s1 = *p;
    uint64_t *block_state1 = s1.block_state;
    uint8_t *buf1 = s1.buf;
    uint64_t total_len1 = s1.total_len;
    uint8_t *k_1 = s1.maybe_key;
    uint64_t x = total_len1 % (uint64_t)(uint32_t)16U;
    uint32_t sz1 = (uint32_t)x;
    uint8_t *buf2 = buf1 + sz1;
    memcpy(buf2, data, len * sizeof (data[0U]));
    uint64_t total_len2 = total_len1 + (uint64_t)len;
    *p
    =
      (
        (Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_){
          .block_state = block_state1,
          .buf = buf1,
          .total_len = total_len2,
          .maybe_key = k_1
        }
      );
    return;
  }
  if (sz == (uint32_t)0U)
  {
    Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ s1 = *p;
    uint64_t *block_state1 = s1.block_state;
    uint8_t *buf1 = s1.buf;
    uint64_t total_len1 = s1.total_len;
    uint8_t *k_1 = s1.maybe_key;
    uint32_t n_blocks = len / (uint32_t)16U;
    uint32_t data1_len = n_blocks * (uint32_t)16U;
    uint32_t data2_len = len - data1_len;
    uint8_t *data1 = data;
    uint8_t *data2 = data + data1_len;
    uint64_t *pre = block_state1 + (uint32_t)5U;
    uint64_t *acc = block_state1;
    uint32_t nb = data1_len / (uint32_t)16U;
    uint32_t rem1 = data1_len % (uint32_t)16U;
    for (uint32_t i = (uint32_t)0U; i < nb; i++)
    {
      uint8_t *block = data1 + i * (uint32_t)16U;
      uint64_t e[5U] = { 0U };
      uint64_t u20 = load64_le(block);
      uint64_t lo = u20;
      uint64_t u2 = load64_le(block + (uint32_t)8U);
      uint64_t hi = u2;
      uint64_t f0 = lo;
      uint64_t f1 = hi;
      uint64_t f010 = f0 & (uint64_t)0x3ffffffU;
      uint64_t f110 = f0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
      uint64_t f20 = f0 >> (uint32_t)52U | (f1 & (uint64_t)0x3fffU) << (uint32_t)12U;
      uint64_t f30 = f1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
      uint64_t f40 = f1 >> (uint32_t)40U;
      uint64_t f01 = f010;
      uint64_t f111 = f110;
      uint64_t f2 = f20;
      uint64_t f3 = f30;
      uint64_t f41 = f40;
      e[0U] = f01;
      e[1U] = f111;
      e[2U] = f2;
      e[3U] = f3;
      e[4U] = f41;
      uint64_t b = (uint64_t)0x1000000U;
      uint64_t mask = b;
      uint64_t f4 = e[4U];
      e[4U] = f4 | mask;
      uint64_t *r = pre;
      uint64_t *r5 = pre + (uint32_t)5U;
      uint64_t r0 = r[0U];
      uint64_t r1 = r[1U];
      uint64_t r2 = r[2U];
      uint64_t r3 = r[3U];
      uint64_t r4 = r[4U];
      uint64_t r51 = r5[1U];
      uint64_t r52 = r5[2U];
      uint64_t r53 = r5[3U];
      uint64_t r54 = r5[4U];
      uint64_t f10 = e[0U];
      uint64_t f11 = e[1U];
      uint64_t f12 = e[2U];
      uint64_t f13 = e[3U];
      uint64_t f14 = e[4U];
      uint64_t a0 = acc[0U];
      uint64_t a1 = acc[1U];
      uint64_t a2 = acc[2U];
      uint64_t a3 = acc[3U];
      uint64_t a4 = acc[4U];
      uint64_t a01 = a0 + f10;
      uint64_t a11 = a1 + f11;
      uint64_t a21 = a2 + f12;
      uint64_t a31 = a3 + f13;
      uint64_t a41 = a4 + f14;
      uint64_t a02 = r0 * a01;
      uint64_t a12 = r1 * a01;
      uint64_t a22 = r2 * a01;
      uint64_t a32 = r3 * a01;
      uint64_t a42 = r4 * a01;
      uint64_t a03 = a02 + r54 * a11;
      uint64_t a13 = a12 + r0 * a11;
      uint64_t a23 = a22 + r1 * a11;
      uint64_t a33 = a32 + r2 * a11;
      uint64_t a43 = a42 + r3 * a11;
      uint64_t a04 = a03 + r53 * a21;
      uint64_t a14 = a13 + r54 * a21;
      uint64_t a24 = a23 + r0 * a21;
      uint64_t a34 = a33 + r1 * a21;
      uint64_t a44 = a43 + r2 * a21;
      uint64_t a05 = a04 + r52 * a31;
      uint64_t a15 = a14 + r53 * a31;
      uint64_t a25 = a24 + r54 * a31;
      uint64_t a35 = a34 + r0 * a31;
      uint64_t a45 = a44 + r1 * a31;
      uint64_t a06 = a05 + r51 * a41;
      uint64_t a16 = a15 + r52 * a41;
      uint64_t a26 = a25 + r53 * a41;
      uint64_t a36 = a35 + r54 * a41;
      uint64_t a46 = a45 + r0 * a41;
      uint64_t t0 = a06;
      uint64_t t1 = a16;
      uint64_t t2 = a26;
      uint64_t t3 = a36;
      uint64_t t4 = a46;
      uint64_t mask261 = (uint64_t)0x3ffffffU;
      uint64_t z0 = t0 >> (uint32_t)26U;
      uint64_t z1 = t3 >> (uint32_t)26U;
      uint64_t x0 = t0 & mask261;
      uint64_t x3 = t3 & mask261;
      uint64_t x1 = t1 + z0;
      uint64_t x4 = t4 + z1;
      uint64_t z01 = x1 >> (uint32_t)26U;
      uint64_t z11 = x4 >> (uint32_t)26U;
      uint64_t t = z11 << (uint32_t)2U;
      uint64_t z12 = z11 + t;
      uint64_t x11 = x1 & mask261;
      uint64_t x41 = x4 & mask261;
      uint64_t x2 = t2 + z01;
      uint64_t x01 = x0 + z12;
      uint64_t z02 = x2 >> (uint32_t)26U;
      uint64_t z13 = x01 >> (uint32_t)26U;
      uint64_t x21 = x2 & mask261;
      uint64_t x02 = x01 & mask261;
      uint64_t x31 = x3 + z02;
      uint64_t x12 = x11 + z13;
      uint64_t z03 = x31 >> (uint32_t)26U;
      uint64_t x32 = x31 & mask261;
      uint64_t x42 = x41 + z03;
      uint64_t o0 = x02;
      uint64_t o1 = x12;
      uint64_t o2 = x21;
      uint64_t o3 = x32;
      uint64_t o4 = x42;
      acc[0U] = o0;
      acc[1U] = o1;
      acc[2U] = o2;
      acc[3U] = o3;
      acc[4U] = o4;
    }
    if (rem1 > (uint32_t)0U)
    {
      uint8_t *last1 = data1 + nb * (uint32_t)16U;
      uint64_t e[5U] = { 0U };
      uint8_t tmp[16U] = { 0U };
      memcpy(tmp, last1, rem1 * sizeof (last1[0U]));
      uint64_t u20 = load64_le(tmp);
      uint64_t lo = u20;
      uint64_t u2 = load64_le(tmp + (uint32_t)8U);
      uint64_t hi = u2;
      uint64_t f0 = lo;
      uint64_t f1 = hi;
      uint64_t f010 = f0 & (uint64_t)0x3ffffffU;
      uint64_t f110 = f0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
      uint64_t f20 = f0 >> (uint32_t)52U | (f1 & (uint64_t)0x3fffU) << (uint32_t)12U;
      uint64_t f30 = f1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
      uint64_t f40 = f1 >> (uint32_t)40U;
      uint64_t f01 = f010;
      uint64_t f111 = f110;
      uint64_t f2 = f20;
      uint64_t f3 = f30;
      uint64_t f4 = f40;
      e[0U] = f01;
      e[1U] = f111;
      e[2U] = f2;
      e[3U] = f3;
      e[4U] = f4;
      uint64_t b = (uint64_t)1U << rem1 * (uint32_t)8U % (uint32_t)26U;
      uint64_t mask = b;
      uint64_t fi = e[rem1 * (uint32_t)8U / (uint32_t)26U];
      e[rem1 * (uint32_t)8U / (uint32_t)26U] = fi | mask;
      uint64_t *r = pre;
      uint64_t *r5 = pre + (uint32_t)5U;
      uint64_t r0 = r[0U];
      uint64_t r1 = r[1U];
      uint64_t r2 = r[2U];
      uint64_t r3 = r[3U];
      uint64_t r4 = r[4U];
      uint64_t r51 = r5[1U];
      uint64_t r52 = r5[2U];
      uint64_t r53 = r5[3U];
      uint64_t r54 = r5[4U];
      uint64_t f10 = e[0U];
      uint64_t f11 = e[1U];
      uint64_t f12 = e[2U];
      uint64_t f13 = e[3U];
      uint64_t f14 = e[4U];
      uint64_t a0 = acc[0U];
      uint64_t a1 = acc[1U];
      uint64_t a2 = acc[2U];
      uint64_t a3 = acc[3U];
      uint64_t a4 = acc[4U];
      uint64_t a01 = a0 + f10;
      uint64_t a11 = a1 + f11;
      uint64_t a21 = a2 + f12;
      uint64_t a31 = a3 + f13;
      uint64_t a41 = a4 + f14;
      uint64_t a02 = r0 * a01;
      uint64_t a12 = r1 * a01;
      uint64_t a22 = r2 * a01;
      uint64_t a32 = r3 * a01;
      uint64_t a42 = r4 * a01;
      uint64_t a03 = a02 + r54 * a11;
      uint64_t a13 = a12 + r0 * a11;
      uint64_t a23 = a22 + r1 * a11;
      uint64_t a33 = a32 + r2 * a11;
      uint64_t a43 = a42 + r3 * a11;
      uint64_t a04 = a03 + r53 * a21;
      uint64_t a14 = a13 + r54 * a21;
      uint64_t a24 = a23 + r0 * a21;
      uint64_t a34 = a33 + r1 * a21;
      uint64_t a44 = a43 + r2 * a21;
      uint64_t a05 = a04 + r52 * a31;
      uint64_t a15 = a14 + r53 * a31;
      uint64_t a25 = a24 + r54 * a31;
      uint64_t a35 = a34 + r0 * a31;
      uint64_t a45 = a44 + r1 * a31;
      uint64_t a06 = a05 + r51 * a41;
      uint64_t a16 = a15 + r52 * a41;
      uint64_t a26 = a25 + r53 * a41;
      uint64_t a36 = a35 + r54 * a41;
      uint64_t a46 = a45 + r0 * a41;
      uint64_t t0 = a06;
      uint64_t t1 = a16;
      uint64_t t2 = a26;
      uint64_t t3 = a36;
      uint64_t t4 = a46;
      uint64_t mask261 = (uint64_t)0x3ffffffU;
      uint64_t z0 = t0 >> (uint32_t)26U;
      uint64_t z1 = t3 >> (uint32_t)26U;
      uint64_t x0 = t0 & mask261;
      uint64_t x3 = t3 & mask261;
      uint64_t x1 = t1 + z0;
      uint64_t x4 = t4 + z1;
      uint64_t z01 = x1 >> (uint32_t)26U;
      uint64_t z11 = x4 >> (uint32_t)26U;
      uint64_t t = z11 << (uint32_t)2U;
      uint64_t z12 = z11 + t;
      uint64_t x11 = x1 & mask261;
      uint64_t x41 = x4 & mask261;
      uint64_t x2 = t2 + z01;
      uint64_t x01 = x0 + z12;
      uint64_t z02 = x2 >> (uint32_t)26U;
      uint64_t z13 = x01 >> (uint32_t)26U;
      uint64_t x21 = x2 & mask261;
      uint64_t x02 = x01 & mask261;
      uint64_t x31 = x3 + z02;
      uint64_t x12 = x11 + z13;
      uint64_t z03 = x31 >> (uint32_t)26U;
      uint64_t x32 = x31 & mask261;
      uint64_t x42 = x41 + z03;
      uint64_t o0 = x02;
      uint64_t o1 = x12;
      uint64_t o2 = x21;
      uint64_t o3 = x32;
      uint64_t o4 = x42;
      acc[0U] = o0;
      acc[1U] = o1;
      acc[2U] = o2;
      acc[3U] = o3;
      acc[4U] = o4;
    }
    uint8_t *dst = buf1;
    memcpy(dst, data2, data2_len * sizeof (data2[0U]));
    *p
    =
      (
        (Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_){
          .block_state = block_state1,
          .buf = buf1,
          .total_len = total_len1 + (uint64_t)len,
          .maybe_key = k_1
        }
      );
    return;
  }
  uint32_t diff = (uint32_t)16U - sz;
  uint8_t *data1 = data;
  uint8_t *data2 = data + diff;
  Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ s1 = *p;
  uint64_t *block_state10 = s1.block_state;
  uint8_t *buf_1 = s1.buf;
  uint64_t total_len10 = s1.total_len;
  uint8_t *k_1 = s1.maybe_key;
  uint64_t x = total_len10 % (uint64_t)(uint32_t)16U;
  uint32_t sz1 = (uint32_t)x;
  uint32_t diff1 = (uint32_t)16U - sz1;
  uint8_t *buf0 = buf_1;
  uint8_t *buf2 = buf0 + sz1;
  memcpy(buf2, data1, diff1 * sizeof (data1[0U]));
  uint64_t *pre0 = block_state10 + (uint32_t)5U;
  uint64_t *acc0 = block_state10;
  uint32_t nb0 = (uint32_t)1U;
  uint32_t rem10 = (uint32_t)0U;
  for (uint32_t i = (uint32_t)0U; i < nb0; i++)
  {
    uint8_t *block = buf0 + i * (uint32_t)16U;
    uint64_t e[5U] = { 0U };
    uint64_t u20 = load64_le(block);
    uint64_t lo = u20;
    uint64_t u2 = load64_le(block + (uint32_t)8U);
    uint64_t hi = u2;
    uint64_t f0 = lo;
    uint64_t f1 = hi;
    uint64_t f010 = f0 & (uint64_t)0x3ffffffU;
    uint64_t f110 = f0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
    uint64_t f20 = f0 >> (uint32_t)52U | (f1 & (uint64_t)0x3fffU) << (uint32_t)12U;
    uint64_t f30 = f1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
    uint64_t f40 = f1 >> (uint32_t)40U;
    uint64_t f01 = f010;
    uint64_t f111 = f110;
    uint64_t f2 = f20;
    uint64_t f3 = f30;
    uint64_t f41 = f40;
    e[0U] = f01;
    e[1U] = f111;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f41;
    uint64_t b = (uint64_t)0x1000000U;
    uint64_t mask = b;
    uint64_t f4 = e[4U];
    e[4U] = f4 | mask;
    uint64_t *r = pre0;
    uint64_t *r5 = pre0 + (uint32_t)5U;
    uint64_t r0 = r[0U];
    uint64_t r1 = r[1U];
    uint64_t r2 = r[2U];
    uint64_t r3 = r[3U];
    uint64_t r4 = r[4U];
    uint64_t r51 = r5[1U];
    uint64_t r52 = r5[2U];
    uint64_t r53 = r5[3U];
    uint64_t r54 = r5[4U];
    uint64_t f10 = e[0U];
    uint64_t f11 = e[1U];
    uint64_t f12 = e[2U];
    uint64_t f13 = e[3U];
    uint64_t f14 = e[4U];
    uint64_t a0 = acc0[0U];
    uint64_t a1 = acc0[1U];
    uint64_t a2 = acc0[2U];
    uint64_t a3 = acc0[3U];
    uint64_t a4 = acc0[4U];
    uint64_t a01 = a0 + f10;
    uint64_t a11 = a1 + f11;
    uint64_t a21 = a2 + f12;
    uint64_t a31 = a3 + f13;
    uint64_t a41 = a4 + f14;
    uint64_t a02 = r0 * a01;
    uint64_t a12 = r1 * a01;
    uint64_t a22 = r2 * a01;
    uint64_t a32 = r3 * a01;
    uint64_t a42 = r4 * a01;
    uint64_t a03 = a02 + r54 * a11;
    uint64_t a13 = a12 + r0 * a11;
    uint64_t a23 = a22 + r1 * a11;
    uint64_t a33 = a32 + r2 * a11;
    uint64_t a43 = a42 + r3 * a11;
    uint64_t a04 = a03 + r53 * a21;
    uint64_t a14 = a13 + r54 * a21;
    uint64_t a24 = a23 + r0 * a21;
    uint64_t a34 = a33 + r1 * a21;
    uint64_t a44 = a43 + r2 * a21;
    uint64_t a05 = a04 + r52 * a31;
    uint64_t a15 = a14 + r53 * a31;
    uint64_t a25 = a24 + r54 * a31;
    uint64_t a35 = a34 + r0 * a31;
    uint64_t a45 = a44 + r1 * a31;
    uint64_t a06 = a05 + r51 * a41;
    uint64_t a16 = a15 + r52 * a41;
    uint64_t a26 = a25 + r53 * a41;
    uint64_t a36 = a35 + r54 * a41;
    uint64_t a46 = a45 + r0 * a41;
    uint64_t t0 = a06;
    uint64_t t1 = a16;
    uint64_t t2 = a26;
    uint64_t t3 = a36;
    uint64_t t4 = a46;
    uint64_t mask261 = (uint64_t)0x3ffffffU;
    uint64_t z0 = t0 >> (uint32_t)26U;
    uint64_t z1 = t3 >> (uint32_t)26U;
    uint64_t x0 = t0 & mask261;
    uint64_t x3 = t3 & mask261;
    uint64_t x1 = t1 + z0;
    uint64_t x4 = t4 + z1;
    uint64_t z01 = x1 >> (uint32_t)26U;
    uint64_t z11 = x4 >> (uint32_t)26U;
    uint64_t t = z11 << (uint32_t)2U;
    uint64_t z12 = z11 + t;
    uint64_t x11 = x1 & mask261;
    uint64_t x41 = x4 & mask261;
    uint64_t x2 = t2 + z01;
    uint64_t x01 = x0 + z12;
    uint64_t z02 = x2 >> (uint32_t)26U;
    uint64_t z13 = x01 >> (uint32_t)26U;
    uint64_t x21 = x2 & mask261;
    uint64_t x02 = x01 & mask261;
    uint64_t x31 = x3 + z02;
    uint64_t x12 = x11 + z13;
    uint64_t z03 = x31 >> (uint32_t)26U;
    uint64_t x32 = x31 & mask261;
    uint64_t x42 = x41 + z03;
    uint64_t o0 = x02;
    uint64_t o1 = x12;
    uint64_t o2 = x21;
    uint64_t o3 = x32;
    uint64_t o4 = x42;
    acc0[0U] = o0;
    acc0[1U] = o1;
    acc0[2U] = o2;
    acc0[3U] = o3;
    acc0[4U] = o4;
  }
  if (rem10 > (uint32_t)0U)
  {
    uint8_t *last1 = buf0 + nb0 * (uint32_t)16U;
    uint64_t e[5U] = { 0U };
    uint8_t tmp[16U] = { 0U };
    memcpy(tmp, last1, rem10 * sizeof (last1[0U]));
    uint64_t u20 = load64_le(tmp);
    uint64_t lo = u20;
    uint64_t u2 = load64_le(tmp + (uint32_t)8U);
    uint64_t hi = u2;
    uint64_t f0 = lo;
    uint64_t f1 = hi;
    uint64_t f010 = f0 & (uint64_t)0x3ffffffU;
    uint64_t f110 = f0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
    uint64_t f20 = f0 >> (uint32_t)52U | (f1 & (uint64_t)0x3fffU) << (uint32_t)12U;
    uint64_t f30 = f1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
    uint64_t f40 = f1 >> (uint32_t)40U;
    uint64_t f01 = f010;
    uint64_t f111 = f110;
    uint64_t f2 = f20;
    uint64_t f3 = f30;
    uint64_t f4 = f40;
    e[0U] = f01;
    e[1U] = f111;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f4;
    uint64_t b = (uint64_t)1U << rem10 * (uint32_t)8U % (uint32_t)26U;
    uint64_t mask = b;
    uint64_t fi = e[rem10 * (uint32_t)8U / (uint32_t)26U];
    e[rem10 * (uint32_t)8U / (uint32_t)26U] = fi | mask;
    uint64_t *r = pre0;
    uint64_t *r5 = pre0 + (uint32_t)5U;
    uint64_t r0 = r[0U];
    uint64_t r1 = r[1U];
    uint64_t r2 = r[2U];
    uint64_t r3 = r[3U];
    uint64_t r4 = r[4U];
    uint64_t r51 = r5[1U];
    uint64_t r52 = r5[2U];
    uint64_t r53 = r5[3U];
    uint64_t r54 = r5[4U];
    uint64_t f10 = e[0U];
    uint64_t f11 = e[1U];
    uint64_t f12 = e[2U];
    uint64_t f13 = e[3U];
    uint64_t f14 = e[4U];
    uint64_t a0 = acc0[0U];
    uint64_t a1 = acc0[1U];
    uint64_t a2 = acc0[2U];
    uint64_t a3 = acc0[3U];
    uint64_t a4 = acc0[4U];
    uint64_t a01 = a0 + f10;
    uint64_t a11 = a1 + f11;
    uint64_t a21 = a2 + f12;
    uint64_t a31 = a3 + f13;
    uint64_t a41 = a4 + f14;
    uint64_t a02 = r0 * a01;
    uint64_t a12 = r1 * a01;
    uint64_t a22 = r2 * a01;
    uint64_t a32 = r3 * a01;
    uint64_t a42 = r4 * a01;
    uint64_t a03 = a02 + r54 * a11;
    uint64_t a13 = a12 + r0 * a11;
    uint64_t a23 = a22 + r1 * a11;
    uint64_t a33 = a32 + r2 * a11;
    uint64_t a43 = a42 + r3 * a11;
    uint64_t a04 = a03 + r53 * a21;
    uint64_t a14 = a13 + r54 * a21;
    uint64_t a24 = a23 + r0 * a21;
    uint64_t a34 = a33 + r1 * a21;
    uint64_t a44 = a43 + r2 * a21;
    uint64_t a05 = a04 + r52 * a31;
    uint64_t a15 = a14 + r53 * a31;
    uint64_t a25 = a24 + r54 * a31;
    uint64_t a35 = a34 + r0 * a31;
    uint64_t a45 = a44 + r1 * a31;
    uint64_t a06 = a05 + r51 * a41;
    uint64_t a16 = a15 + r52 * a41;
    uint64_t a26 = a25 + r53 * a41;
    uint64_t a36 = a35 + r54 * a41;
    uint64_t a46 = a45 + r0 * a41;
    uint64_t t0 = a06;
    uint64_t t1 = a16;
    uint64_t t2 = a26;
    uint64_t t3 = a36;
    uint64_t t4 = a46;
    uint64_t mask261 = (uint64_t)0x3ffffffU;
    uint64_t z0 = t0 >> (uint32_t)26U;
    uint64_t z1 = t3 >> (uint32_t)26U;
    uint64_t x0 = t0 & mask261;
    uint64_t x3 = t3 & mask261;
    uint64_t x1 = t1 + z0;
    uint64_t x4 = t4 + z1;
    uint64_t z01 = x1 >> (uint32_t)26U;
    uint64_t z11 = x4 >> (uint32_t)26U;
    uint64_t t = z11 << (uint32_t)2U;
    uint64_t z12 = z11 + t;
    uint64_t x11 = x1 & mask261;
    uint64_t x41 = x4 & mask261;
    uint64_t x2 = t2 + z01;
    uint64_t x01 = x0 + z12;
    uint64_t z02 = x2 >> (uint32_t)26U;
    uint64_t z13 = x01 >> (uint32_t)26U;
    uint64_t x21 = x2 & mask261;
    uint64_t x02 = x01 & mask261;
    uint64_t x31 = x3 + z02;
    uint64_t x12 = x11 + z13;
    uint64_t z03 = x31 >> (uint32_t)26U;
    uint64_t x32 = x31 & mask261;
    uint64_t x42 = x41 + z03;
    uint64_t o0 = x02;
    uint64_t o1 = x12;
    uint64_t o2 = x21;
    uint64_t o3 = x32;
    uint64_t o4 = x42;
    acc0[0U] = o0;
    acc0[1U] = o1;
    acc0[2U] = o2;
    acc0[3U] = o3;
    acc0[4U] = o4;
  }
  *p
  =
    (
      (Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_){
        .block_state = block_state10,
        .buf = buf_1,
        .total_len = total_len10 + (uint64_t)diff,
        .maybe_key = k_1
      }
    );
  Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ s10 = *p;
  uint64_t *block_state1 = s10.block_state;
  uint8_t *buf1 = s10.buf;
  uint64_t total_len1 = s10.total_len;
  uint8_t *k_10 = s10.maybe_key;
  uint32_t n_blocks = (len - diff) / (uint32_t)16U;
  uint32_t data1_len = n_blocks * (uint32_t)16U;
  uint32_t data2_len = len - diff - data1_len;
  uint8_t *data11 = data2;
  uint8_t *data21 = data2 + data1_len;
  uint64_t *pre = block_state1 + (uint32_t)5U;
  uint64_t *acc = block_state1;
  uint32_t nb = data1_len / (uint32_t)16U;
  uint32_t rem1 = data1_len % (uint32_t)16U;
  for (uint32_t i = (uint32_t)0U; i < nb; i++)
  {
    uint8_t *block = data11 + i * (uint32_t)16U;
    uint64_t e[5U] = { 0U };
    uint64_t u20 = load64_le(block);
    uint64_t lo = u20;
    uint64_t u2 = load64_le(block + (uint32_t)8U);
    uint64_t hi = u2;
    uint64_t f0 = lo;
    uint64_t f1 = hi;
    uint64_t f010 = f0 & (uint64_t)0x3ffffffU;
    uint64_t f110 = f0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
    uint64_t f20 = f0 >> (uint32_t)52U | (f1 & (uint64_t)0x3fffU) << (uint32_t)12U;
    uint64_t f30 = f1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
    uint64_t f40 = f1 >> (uint32_t)40U;
    uint64_t f01 = f010;
    uint64_t f111 = f110;
    uint64_t f2 = f20;
    uint64_t f3 = f30;
    uint64_t f41 = f40;
    e[0U] = f01;
    e[1U] = f111;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f41;
    uint64_t b = (uint64_t)0x1000000U;
    uint64_t mask = b;
    uint64_t f4 = e[4U];
    e[4U] = f4 | mask;
    uint64_t *r = pre;
    uint64_t *r5 = pre + (uint32_t)5U;
    uint64_t r0 = r[0U];
    uint64_t r1 = r[1U];
    uint64_t r2 = r[2U];
    uint64_t r3 = r[3U];
    uint64_t r4 = r[4U];
    uint64_t r51 = r5[1U];
    uint64_t r52 = r5[2U];
    uint64_t r53 = r5[3U];
    uint64_t r54 = r5[4U];
    uint64_t f10 = e[0U];
    uint64_t f11 = e[1U];
    uint64_t f12 = e[2U];
    uint64_t f13 = e[3U];
    uint64_t f14 = e[4U];
    uint64_t a0 = acc[0U];
    uint64_t a1 = acc[1U];
    uint64_t a2 = acc[2U];
    uint64_t a3 = acc[3U];
    uint64_t a4 = acc[4U];
    uint64_t a01 = a0 + f10;
    uint64_t a11 = a1 + f11;
    uint64_t a21 = a2 + f12;
    uint64_t a31 = a3 + f13;
    uint64_t a41 = a4 + f14;
    uint64_t a02 = r0 * a01;
    uint64_t a12 = r1 * a01;
    uint64_t a22 = r2 * a01;
    uint64_t a32 = r3 * a01;
    uint64_t a42 = r4 * a01;
    uint64_t a03 = a02 + r54 * a11;
    uint64_t a13 = a12 + r0 * a11;
    uint64_t a23 = a22 + r1 * a11;
    uint64_t a33 = a32 + r2 * a11;
    uint64_t a43 = a42 + r3 * a11;
    uint64_t a04 = a03 + r53 * a21;
    uint64_t a14 = a13 + r54 * a21;
    uint64_t a24 = a23 + r0 * a21;
    uint64_t a34 = a33 + r1 * a21;
    uint64_t a44 = a43 + r2 * a21;
    uint64_t a05 = a04 + r52 * a31;
    uint64_t a15 = a14 + r53 * a31;
    uint64_t a25 = a24 + r54 * a31;
    uint64_t a35 = a34 + r0 * a31;
    uint64_t a45 = a44 + r1 * a31;
    uint64_t a06 = a05 + r51 * a41;
    uint64_t a16 = a15 + r52 * a41;
    uint64_t a26 = a25 + r53 * a41;
    uint64_t a36 = a35 + r54 * a41;
    uint64_t a46 = a45 + r0 * a41;
    uint64_t t0 = a06;
    uint64_t t1 = a16;
    uint64_t t2 = a26;
    uint64_t t3 = a36;
    uint64_t t4 = a46;
    uint64_t mask261 = (uint64_t)0x3ffffffU;
    uint64_t z0 = t0 >> (uint32_t)26U;
    uint64_t z1 = t3 >> (uint32_t)26U;
    uint64_t x0 = t0 & mask261;
    uint64_t x3 = t3 & mask261;
    uint64_t x1 = t1 + z0;
    uint64_t x4 = t4 + z1;
    uint64_t z01 = x1 >> (uint32_t)26U;
    uint64_t z11 = x4 >> (uint32_t)26U;
    uint64_t t = z11 << (uint32_t)2U;
    uint64_t z12 = z11 + t;
    uint64_t x11 = x1 & mask261;
    uint64_t x41 = x4 & mask261;
    uint64_t x2 = t2 + z01;
    uint64_t x01 = x0 + z12;
    uint64_t z02 = x2 >> (uint32_t)26U;
    uint64_t z13 = x01 >> (uint32_t)26U;
    uint64_t x21 = x2 & mask261;
    uint64_t x02 = x01 & mask261;
    uint64_t x31 = x3 + z02;
    uint64_t x12 = x11 + z13;
    uint64_t z03 = x31 >> (uint32_t)26U;
    uint64_t x32 = x31 & mask261;
    uint64_t x42 = x41 + z03;
    uint64_t o0 = x02;
    uint64_t o1 = x12;
    uint64_t o2 = x21;
    uint64_t o3 = x32;
    uint64_t o4 = x42;
    acc[0U] = o0;
    acc[1U] = o1;
    acc[2U] = o2;
    acc[3U] = o3;
    acc[4U] = o4;
  }
  if (rem1 > (uint32_t)0U)
  {
    uint8_t *last1 = data11 + nb * (uint32_t)16U;
    uint64_t e[5U] = { 0U };
    uint8_t tmp[16U] = { 0U };
    memcpy(tmp, last1, rem1 * sizeof (last1[0U]));
    uint64_t u20 = load64_le(tmp);
    uint64_t lo = u20;
    uint64_t u2 = load64_le(tmp + (uint32_t)8U);
    uint64_t hi = u2;
    uint64_t f0 = lo;
    uint64_t f1 = hi;
    uint64_t f010 = f0 & (uint64_t)0x3ffffffU;
    uint64_t f110 = f0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
    uint64_t f20 = f0 >> (uint32_t)52U | (f1 & (uint64_t)0x3fffU) << (uint32_t)12U;
    uint64_t f30 = f1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
    uint64_t f40 = f1 >> (uint32_t)40U;
    uint64_t f01 = f010;
    uint64_t f111 = f110;
    uint64_t f2 = f20;
    uint64_t f3 = f30;
    uint64_t f4 = f40;
    e[0U] = f01;
    e[1U] = f111;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f4;
    uint64_t b = (uint64_t)1U << rem1 * (uint32_t)8U % (uint32_t)26U;
    uint64_t mask = b;
    uint64_t fi = e[rem1 * (uint32_t)8U / (uint32_t)26U];
    e[rem1 * (uint32_t)8U / (uint32_t)26U] = fi | mask;
    uint64_t *r = pre;
    uint64_t *r5 = pre + (uint32_t)5U;
    uint64_t r0 = r[0U];
    uint64_t r1 = r[1U];
    uint64_t r2 = r[2U];
    uint64_t r3 = r[3U];
    uint64_t r4 = r[4U];
    uint64_t r51 = r5[1U];
    uint64_t r52 = r5[2U];
    uint64_t r53 = r5[3U];
    uint64_t r54 = r5[4U];
    uint64_t f10 = e[0U];
    uint64_t f11 = e[1U];
    uint64_t f12 = e[2U];
    uint64_t f13 = e[3U];
    uint64_t f14 = e[4U];
    uint64_t a0 = acc[0U];
    uint64_t a1 = acc[1U];
    uint64_t a2 = acc[2U];
    uint64_t a3 = acc[3U];
    uint64_t a4 = acc[4U];
    uint64_t a01 = a0 + f10;
    uint64_t a11 = a1 + f11;
    uint64_t a21 = a2 + f12;
    uint64_t a31 = a3 + f13;
    uint64_t a41 = a4 + f14;
    uint64_t a02 = r0 * a01;
    uint64_t a12 = r1 * a01;
    uint64_t a22 = r2 * a01;
    uint64_t a32 = r3 * a01;
    uint64_t a42 = r4 * a01;
    uint64_t a03 = a02 + r54 * a11;
    uint64_t a13 = a12 + r0 * a11;
    uint64_t a23 = a22 + r1 * a11;
    uint64_t a33 = a32 + r2 * a11;
    uint64_t a43 = a42 + r3 * a11;
    uint64_t a04 = a03 + r53 * a21;
    uint64_t a14 = a13 + r54 * a21;
    uint64_t a24 = a23 + r0 * a21;
    uint64_t a34 = a33 + r1 * a21;
    uint64_t a44 = a43 + r2 * a21;
    uint64_t a05 = a04 + r52 * a31;
    uint64_t a15 = a14 + r53 * a31;
    uint64_t a25 = a24 + r54 * a31;
    uint64_t a35 = a34 + r0 * a31;
    uint64_t a45 = a44 + r1 * a31;
    uint64_t a06 = a05 + r51 * a41;
    uint64_t a16 = a15 + r52 * a41;
    uint64_t a26 = a25 + r53 * a41;
    uint64_t a36 = a35 + r54 * a41;
    uint64_t a46 = a45 + r0 * a41;
    uint64_t t0 = a06;
    uint64_t t1 = a16;
    uint64_t t2 = a26;
    uint64_t t3 = a36;
    uint64_t t4 = a46;
    uint64_t mask261 = (uint64_t)0x3ffffffU;
    uint64_t z0 = t0 >> (uint32_t)26U;
    uint64_t z1 = t3 >> (uint32_t)26U;
    uint64_t x0 = t0 & mask261;
    uint64_t x3 = t3 & mask261;
    uint64_t x1 = t1 + z0;
    uint64_t x4 = t4 + z1;
    uint64_t z01 = x1 >> (uint32_t)26U;
    uint64_t z11 = x4 >> (uint32_t)26U;
    uint64_t t = z11 << (uint32_t)2U;
    uint64_t z12 = z11 + t;
    uint64_t x11 = x1 & mask261;
    uint64_t x41 = x4 & mask261;
    uint64_t x2 = t2 + z01;
    uint64_t x01 = x0 + z12;
    uint64_t z02 = x2 >> (uint32_t)26U;
    uint64_t z13 = x01 >> (uint32_t)26U;
    uint64_t x21 = x2 & mask261;
    uint64_t x02 = x01 & mask261;
    uint64_t x31 = x3 + z02;
    uint64_t x12 = x11 + z13;
    uint64_t z03 = x31 >> (uint32_t)26U;
    uint64_t x32 = x31 & mask261;
    uint64_t x42 = x41 + z03;
    uint64_t o0 = x02;
    uint64_t o1 = x12;
    uint64_t o2 = x21;
    uint64_t o3 = x32;
    uint64_t o4 = x42;
    acc[0U] = o0;
    acc[1U] = o1;
    acc[2U] = o2;
    acc[3U] = o3;
    acc[4U] = o4;
  }
  uint8_t *dst = buf1;
  memcpy(dst, data21, data2_len * sizeof (data21[0U]));
  *p
  =
    (
      (Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_){
        .block_state = block_state1,
        .buf = buf1,
        .total_len = total_len1 + (uint64_t)(len - diff),
        .maybe_key = k_10
      }
    );
}

void
Hacl_Streaming_Poly1305_32_finish(
  Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ *p,
  uint8_t *dst
)
{
  Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ scrut = *p;
  uint64_t *block_state = scrut.block_state;
  uint8_t *buf_ = scrut.buf;
  uint64_t total_len = scrut.total_len;
  uint8_t *k_ = scrut.maybe_key;
  uint8_t *buf_1 = buf_;
  uint8_t dummy_key[32U] = { 0U };
  uint64_t r[25U] = { 0U };
  uint64_t *acc0 = r;
  uint64_t *pre0 = r + (uint32_t)5U;
  uint8_t *kr = dummy_key;
  acc0[0U] = (uint64_t)0U;
  acc0[1U] = (uint64_t)0U;
  acc0[2U] = (uint64_t)0U;
  acc0[3U] = (uint64_t)0U;
  acc0[4U] = (uint64_t)0U;
  uint64_t u20 = load64_le(kr);
  uint64_t lo0 = u20;
  uint64_t u21 = load64_le(kr + (uint32_t)8U);
  uint64_t hi0 = u21;
  uint64_t mask0 = (uint64_t)0x0ffffffc0fffffffU;
  uint64_t mask1 = (uint64_t)0x0ffffffc0ffffffcU;
  uint64_t lo1 = lo0 & mask0;
  uint64_t hi1 = hi0 & mask1;
  uint64_t *r10 = pre0;
  uint64_t *r50 = pre0 + (uint32_t)5U;
  uint64_t *rn = pre0 + (uint32_t)10U;
  uint64_t *rn_5 = pre0 + (uint32_t)15U;
  uint64_t r_vec0 = lo1;
  uint64_t r_vec1 = hi1;
  uint64_t f00 = r_vec0 & (uint64_t)0x3ffffffU;
  uint64_t f15 = r_vec0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
  uint64_t f25 = r_vec0 >> (uint32_t)52U | (r_vec1 & (uint64_t)0x3fffU) << (uint32_t)12U;
  uint64_t f33 = r_vec1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
  uint64_t f40 = r_vec1 >> (uint32_t)40U;
  uint64_t f02 = f00;
  uint64_t f16 = f15;
  uint64_t f26 = f25;
  uint64_t f34 = f33;
  uint64_t f43 = f40;
  r10[0U] = f02;
  r10[1U] = f16;
  r10[2U] = f26;
  r10[3U] = f34;
  r10[4U] = f43;
  uint64_t f200 = r10[0U];
  uint64_t f210 = r10[1U];
  uint64_t f220 = r10[2U];
  uint64_t f23 = r10[3U];
  uint64_t f24 = r10[4U];
  r50[0U] = f200 * (uint64_t)5U;
  r50[1U] = f210 * (uint64_t)5U;
  r50[2U] = f220 * (uint64_t)5U;
  r50[3U] = f23 * (uint64_t)5U;
  r50[4U] = f24 * (uint64_t)5U;
  rn[0U] = r10[0U];
  rn[1U] = r10[1U];
  rn[2U] = r10[2U];
  rn[3U] = r10[3U];
  rn[4U] = r10[4U];
  rn_5[0U] = r50[0U];
  rn_5[1U] = r50[1U];
  rn_5[2U] = r50[2U];
  rn_5[3U] = r50[3U];
  rn_5[4U] = r50[4U];
  uint64_t *tmp_block_state = r;
  memcpy(tmp_block_state, block_state, (uint32_t)25U * sizeof (block_state[0U]));
  uint32_t len = (uint32_t)(total_len % (uint64_t)16U);
  if (len != (uint32_t)0U)
  {
    uint64_t *pre = tmp_block_state + (uint32_t)5U;
    uint64_t *acc = tmp_block_state;
    uint32_t nb = len / (uint32_t)16U;
    uint32_t rem1 = len % (uint32_t)16U;
    for (uint32_t i = (uint32_t)0U; i < nb; i++)
    {
      uint8_t *block = buf_1 + i * (uint32_t)16U;
      uint64_t e[5U] = { 0U };
      uint64_t u22 = load64_le(block);
      uint64_t lo = u22;
      uint64_t u2 = load64_le(block + (uint32_t)8U);
      uint64_t hi = u2;
      uint64_t f0 = lo;
      uint64_t f1 = hi;
      uint64_t f010 = f0 & (uint64_t)0x3ffffffU;
      uint64_t f110 = f0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
      uint64_t f20 = f0 >> (uint32_t)52U | (f1 & (uint64_t)0x3fffU) << (uint32_t)12U;
      uint64_t f30 = f1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
      uint64_t f41 = f1 >> (uint32_t)40U;
      uint64_t f01 = f010;
      uint64_t f111 = f110;
      uint64_t f2 = f20;
      uint64_t f3 = f30;
      uint64_t f42 = f41;
      e[0U] = f01;
      e[1U] = f111;
      e[2U] = f2;
      e[3U] = f3;
      e[4U] = f42;
      uint64_t b = (uint64_t)0x1000000U;
      uint64_t mask = b;
      uint64_t f4 = e[4U];
      e[4U] = f4 | mask;
      uint64_t *r6 = pre;
      uint64_t *r5 = pre + (uint32_t)5U;
      uint64_t r0 = r6[0U];
      uint64_t r1 = r6[1U];
      uint64_t r2 = r6[2U];
      uint64_t r3 = r6[3U];
      uint64_t r4 = r6[4U];
      uint64_t r51 = r5[1U];
      uint64_t r52 = r5[2U];
      uint64_t r53 = r5[3U];
      uint64_t r54 = r5[4U];
      uint64_t f10 = e[0U];
      uint64_t f11 = e[1U];
      uint64_t f12 = e[2U];
      uint64_t f13 = e[3U];
      uint64_t f14 = e[4U];
      uint64_t a0 = acc[0U];
      uint64_t a1 = acc[1U];
      uint64_t a2 = acc[2U];
      uint64_t a3 = acc[3U];
      uint64_t a4 = acc[4U];
      uint64_t a01 = a0 + f10;
      uint64_t a11 = a1 + f11;
      uint64_t a21 = a2 + f12;
      uint64_t a31 = a3 + f13;
      uint64_t a41 = a4 + f14;
      uint64_t a02 = r0 * a01;
      uint64_t a12 = r1 * a01;
      uint64_t a22 = r2 * a01;
      uint64_t a32 = r3 * a01;
      uint64_t a42 = r4 * a01;
      uint64_t a03 = a02 + r54 * a11;
      uint64_t a13 = a12 + r0 * a11;
      uint64_t a23 = a22 + r1 * a11;
      uint64_t a33 = a32 + r2 * a11;
      uint64_t a43 = a42 + r3 * a11;
      uint64_t a04 = a03 + r53 * a21;
      uint64_t a14 = a13 + r54 * a21;
      uint64_t a24 = a23 + r0 * a21;
      uint64_t a34 = a33 + r1 * a21;
      uint64_t a44 = a43 + r2 * a21;
      uint64_t a05 = a04 + r52 * a31;
      uint64_t a15 = a14 + r53 * a31;
      uint64_t a25 = a24 + r54 * a31;
      uint64_t a35 = a34 + r0 * a31;
      uint64_t a45 = a44 + r1 * a31;
      uint64_t a06 = a05 + r51 * a41;
      uint64_t a16 = a15 + r52 * a41;
      uint64_t a26 = a25 + r53 * a41;
      uint64_t a36 = a35 + r54 * a41;
      uint64_t a46 = a45 + r0 * a41;
      uint64_t t0 = a06;
      uint64_t t1 = a16;
      uint64_t t2 = a26;
      uint64_t t3 = a36;
      uint64_t t4 = a46;
      uint64_t mask261 = (uint64_t)0x3ffffffU;
      uint64_t z0 = t0 >> (uint32_t)26U;
      uint64_t z1 = t3 >> (uint32_t)26U;
      uint64_t x0 = t0 & mask261;
      uint64_t x3 = t3 & mask261;
      uint64_t x1 = t1 + z0;
      uint64_t x4 = t4 + z1;
      uint64_t z01 = x1 >> (uint32_t)26U;
      uint64_t z11 = x4 >> (uint32_t)26U;
      uint64_t t = z11 << (uint32_t)2U;
      uint64_t z12 = z11 + t;
      uint64_t x11 = x1 & mask261;
      uint64_t x41 = x4 & mask261;
      uint64_t x2 = t2 + z01;
      uint64_t x01 = x0 + z12;
      uint64_t z02 = x2 >> (uint32_t)26U;
      uint64_t z13 = x01 >> (uint32_t)26U;
      uint64_t x21 = x2 & mask261;
      uint64_t x02 = x01 & mask261;
      uint64_t x31 = x3 + z02;
      uint64_t x12 = x11 + z13;
      uint64_t z03 = x31 >> (uint32_t)26U;
      uint64_t x32 = x31 & mask261;
      uint64_t x42 = x41 + z03;
      uint64_t o0 = x02;
      uint64_t o1 = x12;
      uint64_t o2 = x21;
      uint64_t o3 = x32;
      uint64_t o4 = x42;
      acc[0U] = o0;
      acc[1U] = o1;
      acc[2U] = o2;
      acc[3U] = o3;
      acc[4U] = o4;
    }
    if (rem1 > (uint32_t)0U)
    {
      uint8_t *last1 = buf_1 + nb * (uint32_t)16U;
      uint64_t e[5U] = { 0U };
      uint8_t tmp[16U] = { 0U };
      memcpy(tmp, last1, rem1 * sizeof (last1[0U]));
      uint64_t u22 = load64_le(tmp);
      uint64_t lo = u22;
      uint64_t u2 = load64_le(tmp + (uint32_t)8U);
      uint64_t hi = u2;
      uint64_t f0 = lo;
      uint64_t f1 = hi;
      uint64_t f010 = f0 & (uint64_t)0x3ffffffU;
      uint64_t f110 = f0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
      uint64_t f20 = f0 >> (uint32_t)52U | (f1 & (uint64_t)0x3fffU) << (uint32_t)12U;
      uint64_t f30 = f1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
      uint64_t f41 = f1 >> (uint32_t)40U;
      uint64_t f01 = f010;
      uint64_t f111 = f110;
      uint64_t f2 = f20;
      uint64_t f3 = f30;
      uint64_t f4 = f41;
      e[0U] = f01;
      e[1U] = f111;
      e[2U] = f2;
      e[3U] = f3;
      e[4U] = f4;
      uint64_t b = (uint64_t)1U << rem1 * (uint32_t)8U % (uint32_t)26U;
      uint64_t mask = b;
      uint64_t fi = e[rem1 * (uint32_t)8U / (uint32_t)26U];
      e[rem1 * (uint32_t)8U / (uint32_t)26U] = fi | mask;
      uint64_t *r6 = pre;
      uint64_t *r5 = pre + (uint32_t)5U;
      uint64_t r0 = r6[0U];
      uint64_t r1 = r6[1U];
      uint64_t r2 = r6[2U];
      uint64_t r3 = r6[3U];
      uint64_t r4 = r6[4U];
      uint64_t r51 = r5[1U];
      uint64_t r52 = r5[2U];
      uint64_t r53 = r5[3U];
      uint64_t r54 = r5[4U];
      uint64_t f10 = e[0U];
      uint64_t f11 = e[1U];
      uint64_t f12 = e[2U];
      uint64_t f13 = e[3U];
      uint64_t f14 = e[4U];
      uint64_t a0 = acc[0U];
      uint64_t a1 = acc[1U];
      uint64_t a2 = acc[2U];
      uint64_t a3 = acc[3U];
      uint64_t a4 = acc[4U];
      uint64_t a01 = a0 + f10;
      uint64_t a11 = a1 + f11;
      uint64_t a21 = a2 + f12;
      uint64_t a31 = a3 + f13;
      uint64_t a41 = a4 + f14;
      uint64_t a02 = r0 * a01;
      uint64_t a12 = r1 * a01;
      uint64_t a22 = r2 * a01;
      uint64_t a32 = r3 * a01;
      uint64_t a42 = r4 * a01;
      uint64_t a03 = a02 + r54 * a11;
      uint64_t a13 = a12 + r0 * a11;
      uint64_t a23 = a22 + r1 * a11;
      uint64_t a33 = a32 + r2 * a11;
      uint64_t a43 = a42 + r3 * a11;
      uint64_t a04 = a03 + r53 * a21;
      uint64_t a14 = a13 + r54 * a21;
      uint64_t a24 = a23 + r0 * a21;
      uint64_t a34 = a33 + r1 * a21;
      uint64_t a44 = a43 + r2 * a21;
      uint64_t a05 = a04 + r52 * a31;
      uint64_t a15 = a14 + r53 * a31;
      uint64_t a25 = a24 + r54 * a31;
      uint64_t a35 = a34 + r0 * a31;
      uint64_t a45 = a44 + r1 * a31;
      uint64_t a06 = a05 + r51 * a41;
      uint64_t a16 = a15 + r52 * a41;
      uint64_t a26 = a25 + r53 * a41;
      uint64_t a36 = a35 + r54 * a41;
      uint64_t a46 = a45 + r0 * a41;
      uint64_t t0 = a06;
      uint64_t t1 = a16;
      uint64_t t2 = a26;
      uint64_t t3 = a36;
      uint64_t t4 = a46;
      uint64_t mask261 = (uint64_t)0x3ffffffU;
      uint64_t z0 = t0 >> (uint32_t)26U;
      uint64_t z1 = t3 >> (uint32_t)26U;
      uint64_t x0 = t0 & mask261;
      uint64_t x3 = t3 & mask261;
      uint64_t x1 = t1 + z0;
      uint64_t x4 = t4 + z1;
      uint64_t z01 = x1 >> (uint32_t)26U;
      uint64_t z11 = x4 >> (uint32_t)26U;
      uint64_t t = z11 << (uint32_t)2U;
      uint64_t z12 = z11 + t;
      uint64_t x11 = x1 & mask261;
      uint64_t x41 = x4 & mask261;
      uint64_t x2 = t2 + z01;
      uint64_t x01 = x0 + z12;
      uint64_t z02 = x2 >> (uint32_t)26U;
      uint64_t z13 = x01 >> (uint32_t)26U;
      uint64_t x21 = x2 & mask261;
      uint64_t x02 = x01 & mask261;
      uint64_t x31 = x3 + z02;
      uint64_t x12 = x11 + z13;
      uint64_t z03 = x31 >> (uint32_t)26U;
      uint64_t x32 = x31 & mask261;
      uint64_t x42 = x41 + z03;
      uint64_t o0 = x02;
      uint64_t o1 = x12;
      uint64_t o2 = x21;
      uint64_t o3 = x32;
      uint64_t o4 = x42;
      acc[0U] = o0;
      acc[1U] = o1;
      acc[2U] = o2;
      acc[3U] = o3;
      acc[4U] = o4;
    }
  }
  uint64_t tmp[25U] = { 0U };
  memcpy(tmp, tmp_block_state, (uint32_t)25U * sizeof (tmp_block_state[0U]));
  uint64_t *acc = tmp;
  uint8_t *ks = k_ + (uint32_t)16U;
  uint64_t f0 = acc[0U];
  uint64_t f13 = acc[1U];
  uint64_t f27 = acc[2U];
  uint64_t f35 = acc[3U];
  uint64_t f44 = acc[4U];
  uint64_t l0 = f0 + (uint64_t)0U;
  uint64_t tmp00 = l0 & (uint64_t)0x3ffffffU;
  uint64_t c00 = l0 >> (uint32_t)26U;
  uint64_t l1 = f13 + c00;
  uint64_t tmp10 = l1 & (uint64_t)0x3ffffffU;
  uint64_t c10 = l1 >> (uint32_t)26U;
  uint64_t l2 = f27 + c10;
  uint64_t tmp20 = l2 & (uint64_t)0x3ffffffU;
  uint64_t c20 = l2 >> (uint32_t)26U;
  uint64_t l3 = f35 + c20;
  uint64_t tmp30 = l3 & (uint64_t)0x3ffffffU;
  uint64_t c30 = l3 >> (uint32_t)26U;
  uint64_t l4 = f44 + c30;
  uint64_t tmp40 = l4 & (uint64_t)0x3ffffffU;
  uint64_t c40 = l4 >> (uint32_t)26U;
  uint64_t f010 = tmp00 + c40 * (uint64_t)5U;
  uint64_t f110 = tmp10;
  uint64_t f211 = tmp20;
  uint64_t f310 = tmp30;
  uint64_t f410 = tmp40;
  uint64_t l = f010 + (uint64_t)0U;
  uint64_t tmp0 = l & (uint64_t)0x3ffffffU;
  uint64_t c0 = l >> (uint32_t)26U;
  uint64_t l5 = f110 + c0;
  uint64_t tmp1 = l5 & (uint64_t)0x3ffffffU;
  uint64_t c1 = l5 >> (uint32_t)26U;
  uint64_t l6 = f211 + c1;
  uint64_t tmp2 = l6 & (uint64_t)0x3ffffffU;
  uint64_t c2 = l6 >> (uint32_t)26U;
  uint64_t l7 = f310 + c2;
  uint64_t tmp3 = l7 & (uint64_t)0x3ffffffU;
  uint64_t c3 = l7 >> (uint32_t)26U;
  uint64_t l8 = f410 + c3;
  uint64_t tmp4 = l8 & (uint64_t)0x3ffffffU;
  uint64_t c4 = l8 >> (uint32_t)26U;
  uint64_t f020 = tmp0 + c4 * (uint64_t)5U;
  uint64_t f12 = tmp1;
  uint64_t f22 = tmp2;
  uint64_t f32 = tmp3;
  uint64_t f42 = tmp4;
  uint64_t mh = (uint64_t)0x3ffffffU;
  uint64_t ml = (uint64_t)0x3fffffbU;
  uint64_t mask = FStar_UInt64_eq_mask(f42, mh);
  uint64_t mask10 = mask & FStar_UInt64_eq_mask(f32, mh);
  uint64_t mask2 = mask10 & FStar_UInt64_eq_mask(f22, mh);
  uint64_t mask3 = mask2 & FStar_UInt64_eq_mask(f12, mh);
  uint64_t mask4 = mask3 & ~~FStar_UInt64_gte_mask(f020, ml);
  uint64_t ph = mask4 & mh;
  uint64_t pl = mask4 & ml;
  uint64_t o0 = f020 - pl;
  uint64_t o1 = f12 - ph;
  uint64_t o2 = f22 - ph;
  uint64_t o3 = f32 - ph;
  uint64_t o4 = f42 - ph;
  uint64_t f011 = o0;
  uint64_t f111 = o1;
  uint64_t f212 = o2;
  uint64_t f311 = o3;
  uint64_t f411 = o4;
  acc[0U] = f011;
  acc[1U] = f111;
  acc[2U] = f212;
  acc[3U] = f311;
  acc[4U] = f411;
  uint64_t f03 = acc[0U];
  uint64_t f1 = acc[1U];
  uint64_t f2 = acc[2U];
  uint64_t f3 = acc[3U];
  uint64_t f4 = acc[4U];
  uint64_t f01 = f03;
  uint64_t f112 = f1;
  uint64_t f213 = f2;
  uint64_t f312 = f3;
  uint64_t f41 = f4;
  uint64_t lo = (f01 | f112 << (uint32_t)26U) | f213 << (uint32_t)52U;
  uint64_t hi = (f213 >> (uint32_t)12U | f312 << (uint32_t)14U) | f41 << (uint32_t)40U;
  uint64_t f10 = lo;
  uint64_t f11 = hi;
  uint64_t u22 = load64_le(ks);
  uint64_t lo2 = u22;
  uint64_t u2 = load64_le(ks + (uint32_t)8U);
  uint64_t hi2 = u2;
  uint64_t f20 = lo2;
  uint64_t f21 = hi2;
  uint64_t r0 = f10 + f20;
  uint64_t r1 = f11 + f21;
  uint64_t c = (r0 ^ ((r0 ^ f20) | ((r0 - f20) ^ f20))) >> (uint32_t)63U;
  uint64_t r11 = r1 + c;
  uint64_t f30 = r0;
  uint64_t f31 = r11;
  store64_le(dst, f30);
  store64_le(dst + (uint32_t)8U, f31);
}

void Hacl_Streaming_Poly1305_32_free(Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ *s)
{
  Hacl_Streaming_Functor_state_s___uint64_t___uint8_t_ scrut = *s;
  uint8_t *k_ = scrut.maybe_key;
  uint8_t *buf1 = scrut.buf;
  uint64_t *block_state = scrut.block_state;
  KRML_HOST_FREE(k_);
  KRML_HOST_FREE(block_state);
  KRML_HOST_FREE(buf1);
  KRML_HOST_FREE(s);
}

